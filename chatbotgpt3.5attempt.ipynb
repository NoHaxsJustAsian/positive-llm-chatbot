{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (4.39.3)\n",
      "Requirement already satisfied: flask in c:\\python311\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (2.31.0)\n",
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python311\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\python311\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\python311\\lib\\site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\python311\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\python311\\lib\\site-packages (from flask) (1.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers flask beautifulsoup4 requests nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (0.29.1)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.29.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\python311\\lib\\site-packages (from accelerate) (2.2.2+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\python311\\lib\\site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.29.1\n",
      "    Uninstalling accelerate-0.29.1:\n",
      "      Successfully uninstalled accelerate-0.29.1\n",
      "  Rolling back uninstall of accelerate\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\scripts\\accelerate-config.exe\n",
      "   from C:\\Users\\WinTo\\AppData\\Local\\Temp\\pip-uninstall-udi26dj8\\accelerate-config.exe\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\scripts\\accelerate-estimate-memory.exe\n",
      "   from C:\\Users\\WinTo\\AppData\\Local\\Temp\\pip-uninstall-udi26dj8\\accelerate-estimate-memory.exe\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\scripts\\accelerate-launch.exe\n",
      "   from C:\\Users\\WinTo\\AppData\\Local\\Temp\\pip-uninstall-udi26dj8\\accelerate-launch.exe\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\scripts\\accelerate.exe\n",
      "   from C:\\Users\\WinTo\\AppData\\Local\\Temp\\pip-uninstall-udi26dj8\\accelerate.exe\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages\\accelerate-0.29.1.dist-info\\\n",
      "   from C:\\Users\\WinTo\\AppData\\Roaming\\Python\\Python311\\site-packages\\~ccelerate-0.29.1.dist-info\n",
      "  Moving to c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages\\accelerate\\\n",
      "   from C:\\Users\\WinTo\\AppData\\Roaming\\Python\\Python311\\site-packages\\~ccelerate\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python311\\\\Scripts\\\\accelerate.exe' -> 'c:\\\\Python311\\\\Scripts\\\\accelerate.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPTNeoForCausalLM, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and model setup\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
    "model = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, inputs, outputs, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.inputs[idx]\n",
    "        output_text = self.outputs[idx]\n",
    "        \n",
    "        input_encodings = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "        output_encodings = tokenizer(output_text, padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_encodings['input_ids']),\n",
    "            \"attention_mask\": torch.tensor(input_encodings['attention_mask']),\n",
    "            \"labels\": torch.tensor(output_encodings['input_ids'])\n",
    "        }\n",
    "    \n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_json('Psychology-10K.json')\n",
    "inputs = df['input'].tolist()\n",
    "outputs = df['output'].tolist()\n",
    "dataset = TextDataset(tokenizer, inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Training arguments and setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=5,\n",
    "    per_device_eval_batch_size=5, \n",
    "    logging_steps=10,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbdfe918ec42eeb2998bc4b9248798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7832, 'grad_norm': 233393.8125, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7063, 'grad_norm': 257102.78125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.7028, 'grad_norm': 105453.71875, 'learning_rate': 3e-06, 'epoch': 0.02}\n",
      "{'loss': 1.3977, 'grad_norm': 364785.75, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.4128, 'grad_norm': 18980.697265625, 'learning_rate': 5e-06, 'epoch': 0.03}\n",
      "{'loss': 1.3583, 'grad_norm': 63940.2734375, 'learning_rate': 6e-06, 'epoch': 0.03}\n",
      "{'loss': 1.2922, 'grad_norm': 24337.361328125, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 1.2159, 'grad_norm': 50195.70703125, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.04}\n",
      "{'loss': 1.2432, 'grad_norm': 24527.345703125, 'learning_rate': 9e-06, 'epoch': 0.05}\n",
      "{'loss': 1.2736, 'grad_norm': 14798.7236328125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.2911, 'grad_norm': 12435.9921875, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3063, 'grad_norm': 40912.06640625, 'learning_rate': 1.2e-05, 'epoch': 0.06}\n",
      "{'loss': 1.2098, 'grad_norm': 17597.7109375, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.07}\n",
      "{'loss': 1.308, 'grad_norm': 5575.20849609375, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.07}\n",
      "{'loss': 1.3265, 'grad_norm': 6197.58642578125, 'learning_rate': 1.5e-05, 'epoch': 0.08}\n",
      "{'loss': 1.2003, 'grad_norm': 46256.11328125, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.08}\n",
      "{'loss': 1.1937, 'grad_norm': 109996.25, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.09}\n",
      "{'loss': 1.23, 'grad_norm': 358143.6875, 'learning_rate': 1.8e-05, 'epoch': 0.09}\n",
      "{'loss': 1.096, 'grad_norm': 82520.5859375, 'learning_rate': 1.9e-05, 'epoch': 0.1}\n",
      "{'loss': 1.1703, 'grad_norm': 20830.892578125, 'learning_rate': 2e-05, 'epoch': 0.1}\n",
      "{'loss': 1.1911, 'grad_norm': 4781.224609375, 'learning_rate': 2.1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.2007, 'grad_norm': 3454.70751953125, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.11}\n",
      "{'loss': 1.19, 'grad_norm': 5161.791015625, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1915, 'grad_norm': 1375.5526123046875, 'learning_rate': 2.4e-05, 'epoch': 0.12}\n",
      "{'loss': 1.1645, 'grad_norm': 1273769.5, 'learning_rate': 2.5e-05, 'epoch': 0.13}\n",
      "{'loss': 1.1024, 'grad_norm': 15821.1484375, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.13}\n",
      "{'loss': 1.1001, 'grad_norm': 1650018.125, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.14}\n",
      "{'loss': 1.1899, 'grad_norm': 3503766.25, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.14}\n",
      "{'loss': 1.2153, 'grad_norm': 3399479.25, 'learning_rate': 2.9e-05, 'epoch': 0.15}\n",
      "{'loss': 1.152, 'grad_norm': 6749063.5, 'learning_rate': 3e-05, 'epoch': 0.15}\n",
      "{'loss': 1.1204, 'grad_norm': 10241147.0, 'learning_rate': 3.1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.2117, 'grad_norm': 2523146.75, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.16}\n",
      "{'loss': 1.2575, 'grad_norm': 13278171.0, 'learning_rate': 3.3e-05, 'epoch': 0.17}\n",
      "{'loss': 1.2215, 'grad_norm': 13966842.0, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.17}\n",
      "{'loss': 1.1307, 'grad_norm': 8028506.5, 'learning_rate': 3.5e-05, 'epoch': 0.18}\n",
      "{'loss': 1.3476, 'grad_norm': 256416144.0, 'learning_rate': 3.6e-05, 'epoch': 0.18}\n",
      "{'loss': 1.184, 'grad_norm': 45612176.0, 'learning_rate': 3.7e-05, 'epoch': 0.19}\n",
      "{'loss': 1.2065, 'grad_norm': 128981904.0, 'learning_rate': 3.8e-05, 'epoch': 0.19}\n",
      "{'loss': 1.183, 'grad_norm': 22398402.0, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.2}\n",
      "{'loss': 1.2254, 'grad_norm': 34092.265625, 'learning_rate': 4e-05, 'epoch': 0.2}\n",
      "{'loss': 1.3122, 'grad_norm': 1157764.25, 'learning_rate': 4.1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.1684, 'grad_norm': 18457254.0, 'learning_rate': 4.2e-05, 'epoch': 0.21}\n",
      "{'loss': 2.6341, 'grad_norm': 6341823.0, 'learning_rate': 4.3e-05, 'epoch': 0.22}\n",
      "{'loss': 3.5645, 'grad_norm': 2032304.875, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.22}\n",
      "{'loss': 4.1456, 'grad_norm': 3063214.75, 'learning_rate': 4.5e-05, 'epoch': 0.23}\n",
      "{'loss': 4.3661, 'grad_norm': 8351196.5, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.23}\n",
      "{'loss': 3.7658, 'grad_norm': 26169150.0, 'learning_rate': 4.7e-05, 'epoch': 0.24}\n",
      "{'loss': 2.7931, 'grad_norm': 79678792.0, 'learning_rate': 4.8e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8522, 'grad_norm': 53141608.0, 'learning_rate': 4.9e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9578, 'grad_norm': 79465368.0, 'learning_rate': 5e-05, 'epoch': 0.25}\n",
      "{'loss': 1.842, 'grad_norm': 148371632.0, 'learning_rate': 4.993224932249323e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7745, 'grad_norm': 189569744.0, 'learning_rate': 4.986449864498645e-05, 'epoch': 0.26}\n",
      "{'loss': 2.0798, 'grad_norm': 74604960.0, 'learning_rate': 4.9796747967479676e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8766, 'grad_norm': 129205912.0, 'learning_rate': 4.97289972899729e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0544, 'grad_norm': 329141856.0, 'learning_rate': 4.966124661246613e-05, 'epoch': 0.28}\n",
      "{'loss': 2.2559, 'grad_norm': 175208256.0, 'learning_rate': 4.959349593495935e-05, 'epoch': 0.28}\n",
      "{'loss': 2.4448, 'grad_norm': 69882000.0, 'learning_rate': 4.952574525745258e-05, 'epoch': 0.29}\n",
      "{'loss': 2.4405, 'grad_norm': 96432544.0, 'learning_rate': 4.9457994579945803e-05, 'epoch': 0.29}\n",
      "{'loss': 2.1147, 'grad_norm': 73695856.0, 'learning_rate': 4.9390243902439024e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1869, 'grad_norm': 47112832.0, 'learning_rate': 4.932249322493225e-05, 'epoch': 0.3}\n",
      "{'loss': 2.1081, 'grad_norm': 26900094.0, 'learning_rate': 4.925474254742548e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8093, 'grad_norm': 291175552.0, 'learning_rate': 4.9186991869918704e-05, 'epoch': 0.31}\n",
      "{'loss': 2.1525, 'grad_norm': 56426264.0, 'learning_rate': 4.9119241192411924e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9102, 'grad_norm': 21574308.0, 'learning_rate': 4.905149051490515e-05, 'epoch': 0.32}\n",
      "{'loss': 2.2563, 'grad_norm': 213804288.0, 'learning_rate': 4.898373983739837e-05, 'epoch': 0.33}\n",
      "{'loss': 2.2641, 'grad_norm': 93273016.0, 'learning_rate': 4.89159891598916e-05, 'epoch': 0.34}\n",
      "{'loss': 2.4728, 'grad_norm': 358999232.0, 'learning_rate': 4.884823848238483e-05, 'epoch': 0.34}\n",
      "{'loss': 2.5428, 'grad_norm': 71296568.0, 'learning_rate': 4.878048780487805e-05, 'epoch': 0.35}\n",
      "{'loss': 2.4726, 'grad_norm': 70311344.0, 'learning_rate': 4.871273712737128e-05, 'epoch': 0.35}\n",
      "{'loss': 2.4854, 'grad_norm': 66693572.0, 'learning_rate': 4.86449864498645e-05, 'epoch': 0.36}\n",
      "{'loss': 2.3684, 'grad_norm': 47040184.0, 'learning_rate': 4.8577235772357725e-05, 'epoch': 0.36}\n",
      "{'loss': 2.2892, 'grad_norm': 2707824.25, 'learning_rate': 4.8509485094850945e-05, 'epoch': 0.37}\n",
      "{'loss': 3.1219, 'grad_norm': 64132392.0, 'learning_rate': 4.844173441734418e-05, 'epoch': 0.37}\n",
      "{'loss': 2.3549, 'grad_norm': 558846656.0, 'learning_rate': 4.8373983739837406e-05, 'epoch': 0.38}\n",
      "{'loss': 2.011, 'grad_norm': 282678336.0, 'learning_rate': 4.8306233062330626e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8246, 'grad_norm': 1085374976.0, 'learning_rate': 4.823848238482385e-05, 'epoch': 0.39}\n",
      "{'loss': 2.4291, 'grad_norm': 25372182.0, 'learning_rate': 4.817073170731707e-05, 'epoch': 0.39}\n",
      "{'loss': 2.2809, 'grad_norm': 80573864.0, 'learning_rate': 4.81029810298103e-05, 'epoch': 0.4}\n",
      "{'loss': 1.4466, 'grad_norm': 33125806.0, 'learning_rate': 4.8035230352303526e-05, 'epoch': 0.4}\n",
      "{'loss': 1.1425, 'grad_norm': 27956.515625, 'learning_rate': 4.796747967479675e-05, 'epoch': 0.41}\n",
      "{'loss': 1.0323, 'grad_norm': 4125.4921875, 'learning_rate': 4.789972899728998e-05, 'epoch': 0.41}\n",
      "{'loss': 1.0364, 'grad_norm': 19591.55078125, 'learning_rate': 4.78319783197832e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0384, 'grad_norm': 7686.58740234375, 'learning_rate': 4.776422764227643e-05, 'epoch': 0.42}\n",
      "{'loss': 1.3718, 'grad_norm': 35151.578125, 'learning_rate': 4.769647696476965e-05, 'epoch': 0.43}\n",
      "{'loss': 0.9116, 'grad_norm': 4053.534912109375, 'learning_rate': 4.7628726287262874e-05, 'epoch': 0.43}\n",
      "{'loss': 0.9104, 'grad_norm': 732.3106689453125, 'learning_rate': 4.75609756097561e-05, 'epoch': 0.44}\n",
      "{'loss': 0.8629, 'grad_norm': 7131.80712890625, 'learning_rate': 4.749322493224933e-05, 'epoch': 0.44}\n",
      "{'loss': 1.1107, 'grad_norm': 1054807.5, 'learning_rate': 4.7425474254742554e-05, 'epoch': 0.45}\n",
      "{'loss': 0.8947, 'grad_norm': 471.43072509765625, 'learning_rate': 4.7357723577235774e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7998, 'grad_norm': 116593.2421875, 'learning_rate': 4.7289972899729e-05, 'epoch': 0.46}\n",
      "{'loss': 0.9445, 'grad_norm': 3573.073486328125, 'learning_rate': 4.722222222222222e-05, 'epoch': 0.46}\n",
      "{'loss': 8.557, 'grad_norm': 13715873.0, 'learning_rate': 4.715447154471545e-05, 'epoch': 0.47}\n",
      "{'loss': 19.255, 'grad_norm': 660374.125, 'learning_rate': 4.7086720867208675e-05, 'epoch': 0.47}\n",
      "{'loss': 23.1994, 'grad_norm': 5287797.0, 'learning_rate': 4.70189701897019e-05, 'epoch': 0.48}\n",
      "{'loss': 24.7699, 'grad_norm': 66572116.0, 'learning_rate': 4.695121951219512e-05, 'epoch': 0.48}\n",
      "{'loss': 26.6466, 'grad_norm': 7106500.0, 'learning_rate': 4.688346883468835e-05, 'epoch': 0.49}\n",
      "{'loss': 29.9604, 'grad_norm': 25412360.0, 'learning_rate': 4.6815718157181575e-05, 'epoch': 0.49}\n",
      "{'loss': 29.0097, 'grad_norm': 269688896.0, 'learning_rate': 4.6747967479674795e-05, 'epoch': 0.5}\n",
      "{'loss': 28.1531, 'grad_norm': 273377760.0, 'learning_rate': 4.668021680216802e-05, 'epoch': 0.5}\n",
      "{'loss': 26.4129, 'grad_norm': 4339899392.0, 'learning_rate': 4.661246612466125e-05, 'epoch': 0.51}\n",
      "{'loss': 22.1438, 'grad_norm': 7325652480.0, 'learning_rate': 4.6544715447154476e-05, 'epoch': 0.51}\n",
      "{'loss': 18.8107, 'grad_norm': 5141649920.0, 'learning_rate': 4.6476964769647696e-05, 'epoch': 0.52}\n",
      "{'loss': 19.5882, 'grad_norm': 244391840.0, 'learning_rate': 4.640921409214092e-05, 'epoch': 0.52}\n",
      "{'loss': 19.5729, 'grad_norm': 471299296.0, 'learning_rate': 4.634146341463415e-05, 'epoch': 0.53}\n",
      "{'loss': 19.8553, 'grad_norm': 215961264.0, 'learning_rate': 4.627371273712737e-05, 'epoch': 0.53}\n",
      "{'loss': 19.1462, 'grad_norm': 166944288.0, 'learning_rate': 4.62059620596206e-05, 'epoch': 0.54}\n",
      "{'loss': 19.2322, 'grad_norm': 723898240.0, 'learning_rate': 4.613821138211382e-05, 'epoch': 0.54}\n",
      "{'loss': 19.0035, 'grad_norm': 309521248.0, 'learning_rate': 4.607046070460705e-05, 'epoch': 0.55}\n",
      "{'loss': 18.8426, 'grad_norm': 409378560.0, 'learning_rate': 4.600271002710027e-05, 'epoch': 0.55}\n",
      "{'loss': 18.7894, 'grad_norm': 7929097216.0, 'learning_rate': 4.59349593495935e-05, 'epoch': 0.56}\n",
      "{'loss': 19.083, 'grad_norm': 332096576.0, 'learning_rate': 4.5867208672086724e-05, 'epoch': 0.56}\n",
      "{'loss': 19.3858, 'grad_norm': 1661973504.0, 'learning_rate': 4.579945799457995e-05, 'epoch': 0.57}\n",
      "{'loss': 19.5504, 'grad_norm': 407034560.0, 'learning_rate': 4.573170731707318e-05, 'epoch': 0.57}\n",
      "{'loss': 19.432, 'grad_norm': 1235857536.0, 'learning_rate': 4.56639566395664e-05, 'epoch': 0.58}\n",
      "{'loss': 19.5504, 'grad_norm': 520980384.0, 'learning_rate': 4.5596205962059624e-05, 'epoch': 0.58}\n",
      "{'loss': 19.5947, 'grad_norm': 430810784.0, 'learning_rate': 4.5528455284552844e-05, 'epoch': 0.59}\n",
      "{'loss': 19.6798, 'grad_norm': 536781536.0, 'learning_rate': 4.546070460704607e-05, 'epoch': 0.59}\n",
      "{'loss': 19.4848, 'grad_norm': 532873184.0, 'learning_rate': 4.53929539295393e-05, 'epoch': 0.6}\n",
      "{'loss': 19.236, 'grad_norm': 608664512.0, 'learning_rate': 4.5325203252032525e-05, 'epoch': 0.6}\n",
      "{'loss': 19.3374, 'grad_norm': 778091072.0, 'learning_rate': 4.525745257452575e-05, 'epoch': 0.61}\n",
      "{'loss': 18.9207, 'grad_norm': 910006976.0, 'learning_rate': 4.518970189701897e-05, 'epoch': 0.61}\n",
      "{'loss': 19.0554, 'grad_norm': 1032564672.0, 'learning_rate': 4.51219512195122e-05, 'epoch': 0.62}\n",
      "{'loss': 18.8417, 'grad_norm': 915287872.0, 'learning_rate': 4.505420054200542e-05, 'epoch': 0.62}\n",
      "{'loss': 19.1837, 'grad_norm': 1151478272.0, 'learning_rate': 4.4986449864498645e-05, 'epoch': 0.63}\n",
      "{'loss': 18.9297, 'grad_norm': 1297946112.0, 'learning_rate': 4.491869918699187e-05, 'epoch': 0.63}\n",
      "{'loss': 19.0573, 'grad_norm': 1270670336.0, 'learning_rate': 4.48509485094851e-05, 'epoch': 0.64}\n",
      "{'loss': 18.7462, 'grad_norm': 2665115904.0, 'learning_rate': 4.4783197831978326e-05, 'epoch': 0.64}\n",
      "{'loss': 18.9894, 'grad_norm': 1459070720.0, 'learning_rate': 4.4715447154471546e-05, 'epoch': 0.65}\n",
      "{'loss': 18.8487, 'grad_norm': 1667494400.0, 'learning_rate': 4.464769647696477e-05, 'epoch': 0.65}\n",
      "{'loss': 18.6316, 'grad_norm': 1675946752.0, 'learning_rate': 4.457994579945799e-05, 'epoch': 0.66}\n",
      "{'loss': 18.5974, 'grad_norm': 1651734272.0, 'learning_rate': 4.451219512195122e-05, 'epoch': 0.66}\n",
      "{'loss': 18.6352, 'grad_norm': 1450909056.0, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.67}\n",
      "{'loss': 18.5219, 'grad_norm': 1805837952.0, 'learning_rate': 4.4376693766937673e-05, 'epoch': 0.68}\n",
      "{'loss': 18.618, 'grad_norm': 1564306432.0, 'learning_rate': 4.43089430894309e-05, 'epoch': 0.68}\n",
      "{'loss': 18.62, 'grad_norm': 1604388864.0, 'learning_rate': 4.424119241192412e-05, 'epoch': 0.69}\n",
      "{'loss': 18.5334, 'grad_norm': 1822463104.0, 'learning_rate': 4.417344173441735e-05, 'epoch': 0.69}\n",
      "{'loss': 18.749, 'grad_norm': 1773090176.0, 'learning_rate': 4.410569105691057e-05, 'epoch': 0.7}\n",
      "{'loss': 18.5942, 'grad_norm': 1573880448.0, 'learning_rate': 4.4037940379403794e-05, 'epoch': 0.7}\n",
      "{'loss': 18.6372, 'grad_norm': 1518563840.0, 'learning_rate': 4.397018970189702e-05, 'epoch': 0.71}\n",
      "{'loss': 18.6053, 'grad_norm': 1679840640.0, 'learning_rate': 4.390243902439025e-05, 'epoch': 0.71}\n",
      "{'loss': 18.657, 'grad_norm': 1555656192.0, 'learning_rate': 4.3834688346883474e-05, 'epoch': 0.72}\n",
      "{'loss': 18.6089, 'grad_norm': 1421461760.0, 'learning_rate': 4.3766937669376695e-05, 'epoch': 0.72}\n",
      "{'loss': 18.5799, 'grad_norm': 1557628672.0, 'learning_rate': 4.369918699186992e-05, 'epoch': 0.73}\n",
      "{'loss': 18.5192, 'grad_norm': 1217309312.0, 'learning_rate': 4.363143631436314e-05, 'epoch': 0.73}\n",
      "{'loss': 18.1277, 'grad_norm': 1528390016.0, 'learning_rate': 4.3563685636856375e-05, 'epoch': 0.74}\n",
      "{'loss': 17.5871, 'grad_norm': 2342954496.0, 'learning_rate': 4.3495934959349595e-05, 'epoch': 0.74}\n",
      "{'loss': 17.4897, 'grad_norm': 1968851584.0, 'learning_rate': 4.342818428184282e-05, 'epoch': 0.75}\n",
      "{'loss': 17.4316, 'grad_norm': 2892837888.0, 'learning_rate': 4.336043360433605e-05, 'epoch': 0.75}\n",
      "{'loss': 17.6592, 'grad_norm': 2292003840.0, 'learning_rate': 4.329268292682927e-05, 'epoch': 0.76}\n",
      "{'loss': 17.5177, 'grad_norm': 2060004736.0, 'learning_rate': 4.3224932249322496e-05, 'epoch': 0.76}\n",
      "{'loss': 17.5706, 'grad_norm': 2523405568.0, 'learning_rate': 4.315718157181572e-05, 'epoch': 0.77}\n",
      "{'loss': 17.5188, 'grad_norm': 2502834944.0, 'learning_rate': 4.308943089430895e-05, 'epoch': 0.77}\n",
      "{'loss': 17.6306, 'grad_norm': 2256524544.0, 'learning_rate': 4.302168021680217e-05, 'epoch': 0.78}\n",
      "{'loss': 17.3994, 'grad_norm': 2181718528.0, 'learning_rate': 4.2953929539295396e-05, 'epoch': 0.78}\n",
      "{'loss': 17.5019, 'grad_norm': 2772781056.0, 'learning_rate': 4.2886178861788616e-05, 'epoch': 0.79}\n",
      "{'loss': 17.5709, 'grad_norm': 2529917440.0, 'learning_rate': 4.281842818428184e-05, 'epoch': 0.79}\n",
      "{'loss': 17.5244, 'grad_norm': 2384130816.0, 'learning_rate': 4.275067750677507e-05, 'epoch': 0.8}\n",
      "{'loss': 17.3794, 'grad_norm': 2513223936.0, 'learning_rate': 4.26829268292683e-05, 'epoch': 0.8}\n",
      "{'loss': 17.6135, 'grad_norm': 3302225152.0, 'learning_rate': 4.2615176151761524e-05, 'epoch': 0.81}\n",
      "{'loss': 17.2082, 'grad_norm': 2665341184.0, 'learning_rate': 4.2547425474254744e-05, 'epoch': 0.81}\n",
      "{'loss': 16.9871, 'grad_norm': 2625559040.0, 'learning_rate': 4.247967479674797e-05, 'epoch': 0.82}\n",
      "{'loss': 16.9974, 'grad_norm': 3030857216.0, 'learning_rate': 4.241192411924119e-05, 'epoch': 0.82}\n",
      "{'loss': 16.8495, 'grad_norm': 4177232640.0, 'learning_rate': 4.234417344173442e-05, 'epoch': 0.83}\n",
      "{'loss': 16.7685, 'grad_norm': 3017196032.0, 'learning_rate': 4.2276422764227644e-05, 'epoch': 0.83}\n",
      "{'loss': 16.8434, 'grad_norm': 3345787904.0, 'learning_rate': 4.220867208672087e-05, 'epoch': 0.84}\n",
      "{'loss': 16.8134, 'grad_norm': 2861922304.0, 'learning_rate': 4.21409214092141e-05, 'epoch': 0.84}\n",
      "{'loss': 16.467, 'grad_norm': 2638523392.0, 'learning_rate': 4.207317073170732e-05, 'epoch': 0.85}\n",
      "{'loss': 16.5007, 'grad_norm': 2873419776.0, 'learning_rate': 4.2005420054200545e-05, 'epoch': 0.85}\n",
      "{'loss': 16.3906, 'grad_norm': 3103668480.0, 'learning_rate': 4.1937669376693765e-05, 'epoch': 0.86}\n",
      "{'loss': 16.3647, 'grad_norm': 3071270912.0, 'learning_rate': 4.186991869918699e-05, 'epoch': 0.86}\n",
      "{'loss': 16.3126, 'grad_norm': 4466916352.0, 'learning_rate': 4.180216802168022e-05, 'epoch': 0.87}\n",
      "{'loss': 16.4489, 'grad_norm': 3395386112.0, 'learning_rate': 4.1734417344173445e-05, 'epoch': 0.87}\n",
      "{'loss': 16.4144, 'grad_norm': 3336977408.0, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.88}\n",
      "{'loss': 16.4374, 'grad_norm': 3616764416.0, 'learning_rate': 4.159891598915989e-05, 'epoch': 0.88}\n",
      "{'loss': 16.5112, 'grad_norm': 3647840000.0, 'learning_rate': 4.153116531165312e-05, 'epoch': 0.89}\n",
      "{'loss': 16.3856, 'grad_norm': 3487898368.0, 'learning_rate': 4.146341463414634e-05, 'epoch': 0.89}\n",
      "{'loss': 16.4289, 'grad_norm': 3726575616.0, 'learning_rate': 4.1395663956639566e-05, 'epoch': 0.9}\n",
      "{'loss': 16.4839, 'grad_norm': 3772441344.0, 'learning_rate': 4.132791327913279e-05, 'epoch': 0.9}\n",
      "{'loss': 16.4649, 'grad_norm': 3789451776.0, 'learning_rate': 4.126016260162602e-05, 'epoch': 0.91}\n",
      "{'loss': 16.5265, 'grad_norm': 4143637248.0, 'learning_rate': 4.1192411924119246e-05, 'epoch': 0.91}\n",
      "{'loss': 16.555, 'grad_norm': 4671500288.0, 'learning_rate': 4.1124661246612466e-05, 'epoch': 0.92}\n",
      "{'loss': 16.5166, 'grad_norm': 4485398528.0, 'learning_rate': 4.105691056910569e-05, 'epoch': 0.92}\n",
      "{'loss': 16.5373, 'grad_norm': 4210082560.0, 'learning_rate': 4.098915989159891e-05, 'epoch': 0.93}\n",
      "{'loss': 16.6182, 'grad_norm': 4513031168.0, 'learning_rate': 4.092140921409214e-05, 'epoch': 0.93}\n",
      "{'loss': 16.5112, 'grad_norm': 4386818048.0, 'learning_rate': 4.085365853658537e-05, 'epoch': 0.94}\n",
      "{'loss': 16.5776, 'grad_norm': 4804595712.0, 'learning_rate': 4.0785907859078594e-05, 'epoch': 0.94}\n",
      "{'loss': 16.5519, 'grad_norm': 4735439360.0, 'learning_rate': 4.071815718157182e-05, 'epoch': 0.95}\n",
      "{'loss': 16.5727, 'grad_norm': 4928107520.0, 'learning_rate': 4.065040650406504e-05, 'epoch': 0.95}\n",
      "{'loss': 16.7319, 'grad_norm': 4966236160.0, 'learning_rate': 4.058265582655827e-05, 'epoch': 0.96}\n",
      "{'loss': 16.5736, 'grad_norm': 5031691264.0, 'learning_rate': 4.051490514905149e-05, 'epoch': 0.96}\n",
      "{'loss': 16.716, 'grad_norm': 5791425536.0, 'learning_rate': 4.044715447154472e-05, 'epoch': 0.97}\n",
      "{'loss': 16.6277, 'grad_norm': 5611974656.0, 'learning_rate': 4.037940379403794e-05, 'epoch': 0.97}\n",
      "{'loss': 16.7116, 'grad_norm': 5909678080.0, 'learning_rate': 4.031165311653117e-05, 'epoch': 0.98}\n",
      "{'loss': 16.7209, 'grad_norm': 5774901248.0, 'learning_rate': 4.0243902439024395e-05, 'epoch': 0.98}\n",
      "{'loss': 16.7683, 'grad_norm': 5992575488.0, 'learning_rate': 4.0176151761517615e-05, 'epoch': 0.99}\n",
      "{'loss': 16.7812, 'grad_norm': 6243823104.0, 'learning_rate': 4.010840108401084e-05, 'epoch': 0.99}\n",
      "{'loss': 16.7965, 'grad_norm': 6442503680.0, 'learning_rate': 4.004065040650407e-05, 'epoch': 1.0}\n",
      "{'loss': 16.779, 'grad_norm': 6494107136.0, 'learning_rate': 3.9972899728997295e-05, 'epoch': 1.01}\n",
      "{'loss': 16.6829, 'grad_norm': 6753495552.0, 'learning_rate': 3.9905149051490515e-05, 'epoch': 1.01}\n",
      "{'loss': 16.8456, 'grad_norm': 6975113216.0, 'learning_rate': 3.983739837398374e-05, 'epoch': 1.02}\n",
      "{'loss': 16.8069, 'grad_norm': 6732014592.0, 'learning_rate': 3.976964769647697e-05, 'epoch': 1.02}\n",
      "{'loss': 16.8475, 'grad_norm': 7155011072.0, 'learning_rate': 3.970189701897019e-05, 'epoch': 1.03}\n",
      "{'loss': 16.8681, 'grad_norm': 7888948224.0, 'learning_rate': 3.9634146341463416e-05, 'epoch': 1.03}\n",
      "{'loss': 16.7911, 'grad_norm': 7625712640.0, 'learning_rate': 3.956639566395664e-05, 'epoch': 1.04}\n",
      "{'loss': 16.9017, 'grad_norm': 7688890368.0, 'learning_rate': 3.949864498644987e-05, 'epoch': 1.04}\n",
      "{'loss': 16.8511, 'grad_norm': 7525863424.0, 'learning_rate': 3.943089430894309e-05, 'epoch': 1.05}\n",
      "{'loss': 16.8695, 'grad_norm': 8365810176.0, 'learning_rate': 3.9363143631436316e-05, 'epoch': 1.05}\n",
      "{'loss': 16.8752, 'grad_norm': 7933712384.0, 'learning_rate': 3.9295392953929537e-05, 'epoch': 1.06}\n",
      "{'loss': 16.8685, 'grad_norm': 7844637696.0, 'learning_rate': 3.922764227642276e-05, 'epoch': 1.06}\n",
      "{'loss': 16.9897, 'grad_norm': 8388670976.0, 'learning_rate': 3.915989159891599e-05, 'epoch': 1.07}\n",
      "{'loss': 16.967, 'grad_norm': 9094312960.0, 'learning_rate': 3.909214092140922e-05, 'epoch': 1.07}\n",
      "{'loss': 16.9838, 'grad_norm': 9460128768.0, 'learning_rate': 3.9024390243902444e-05, 'epoch': 1.08}\n",
      "{'loss': 17.0172, 'grad_norm': 9050601472.0, 'learning_rate': 3.8956639566395664e-05, 'epoch': 1.08}\n",
      "{'loss': 16.9866, 'grad_norm': 9452269568.0, 'learning_rate': 3.888888888888889e-05, 'epoch': 1.09}\n",
      "{'loss': 17.0123, 'grad_norm': 9274886144.0, 'learning_rate': 3.882113821138211e-05, 'epoch': 1.09}\n",
      "{'loss': 17.1111, 'grad_norm': 9647187968.0, 'learning_rate': 3.875338753387534e-05, 'epoch': 1.1}\n",
      "{'loss': 17.1294, 'grad_norm': 10104857600.0, 'learning_rate': 3.8685636856368564e-05, 'epoch': 1.1}\n",
      "{'loss': 17.0809, 'grad_norm': 9953264640.0, 'learning_rate': 3.861788617886179e-05, 'epoch': 1.11}\n",
      "{'loss': 17.1036, 'grad_norm': 10185812992.0, 'learning_rate': 3.855013550135502e-05, 'epoch': 1.11}\n",
      "{'loss': 17.0591, 'grad_norm': 11761878016.0, 'learning_rate': 3.848238482384824e-05, 'epoch': 1.12}\n",
      "{'loss': 17.0388, 'grad_norm': 11099022336.0, 'learning_rate': 3.8414634146341465e-05, 'epoch': 1.12}\n",
      "{'loss': 17.1299, 'grad_norm': 11369521152.0, 'learning_rate': 3.8346883468834685e-05, 'epoch': 1.13}\n",
      "{'loss': 17.1065, 'grad_norm': 11692166144.0, 'learning_rate': 3.827913279132791e-05, 'epoch': 1.13}\n",
      "{'loss': 17.1839, 'grad_norm': 11609007104.0, 'learning_rate': 3.8211382113821145e-05, 'epoch': 1.14}\n",
      "{'loss': 17.2153, 'grad_norm': 12220850176.0, 'learning_rate': 3.8143631436314366e-05, 'epoch': 1.14}\n",
      "{'loss': 17.2755, 'grad_norm': 12085420032.0, 'learning_rate': 3.807588075880759e-05, 'epoch': 1.15}\n",
      "{'loss': 17.2133, 'grad_norm': 12472019968.0, 'learning_rate': 3.800813008130081e-05, 'epoch': 1.15}\n",
      "{'loss': 17.2753, 'grad_norm': 12865447936.0, 'learning_rate': 3.794037940379404e-05, 'epoch': 1.16}\n",
      "{'loss': 17.24, 'grad_norm': 13700850688.0, 'learning_rate': 3.787262872628726e-05, 'epoch': 1.16}\n",
      "{'loss': 17.3099, 'grad_norm': 12588113920.0, 'learning_rate': 3.780487804878049e-05, 'epoch': 1.17}\n",
      "{'loss': 17.2499, 'grad_norm': 12760643584.0, 'learning_rate': 3.773712737127372e-05, 'epoch': 1.17}\n",
      "{'loss': 17.2847, 'grad_norm': 13804882944.0, 'learning_rate': 3.766937669376694e-05, 'epoch': 1.18}\n",
      "{'loss': 17.3976, 'grad_norm': 14454224896.0, 'learning_rate': 3.760162601626017e-05, 'epoch': 1.18}\n",
      "{'loss': 17.2134, 'grad_norm': 14440795136.0, 'learning_rate': 3.753387533875339e-05, 'epoch': 1.19}\n",
      "{'loss': 17.351, 'grad_norm': 14500334592.0, 'learning_rate': 3.7466124661246614e-05, 'epoch': 1.19}\n",
      "{'loss': 17.3496, 'grad_norm': 14974880768.0, 'learning_rate': 3.739837398373984e-05, 'epoch': 1.2}\n",
      "{'loss': 17.4661, 'grad_norm': 14715114496.0, 'learning_rate': 3.733062330623307e-05, 'epoch': 1.2}\n",
      "{'loss': 17.458, 'grad_norm': 15042568192.0, 'learning_rate': 3.726287262872629e-05, 'epoch': 1.21}\n",
      "{'loss': 17.4167, 'grad_norm': 15276097536.0, 'learning_rate': 3.7195121951219514e-05, 'epoch': 1.21}\n",
      "{'loss': 17.4532, 'grad_norm': 15690121216.0, 'learning_rate': 3.712737127371274e-05, 'epoch': 1.22}\n",
      "{'loss': 17.391, 'grad_norm': 16345601024.0, 'learning_rate': 3.705962059620596e-05, 'epoch': 1.22}\n",
      "{'loss': 17.3989, 'grad_norm': 15780214784.0, 'learning_rate': 3.699186991869919e-05, 'epoch': 1.23}\n",
      "{'loss': 17.4619, 'grad_norm': 16513742848.0, 'learning_rate': 3.6924119241192415e-05, 'epoch': 1.23}\n",
      "{'loss': 17.504, 'grad_norm': 16539088896.0, 'learning_rate': 3.685636856368564e-05, 'epoch': 1.24}\n",
      "{'loss': 17.5183, 'grad_norm': 17536808960.0, 'learning_rate': 3.678861788617886e-05, 'epoch': 1.24}\n",
      "{'loss': 17.5015, 'grad_norm': 17033283584.0, 'learning_rate': 3.672086720867209e-05, 'epoch': 1.25}\n",
      "{'loss': 17.5164, 'grad_norm': 20279044096.0, 'learning_rate': 3.6653116531165315e-05, 'epoch': 1.25}\n",
      "{'loss': 17.6724, 'grad_norm': 436271775744.0, 'learning_rate': 3.6585365853658535e-05, 'epoch': 1.26}\n",
      "{'loss': 19.1928, 'grad_norm': 1362809454592.0, 'learning_rate': 3.651761517615176e-05, 'epoch': 1.26}\n",
      "{'loss': 19.1535, 'grad_norm': 3905453031424.0, 'learning_rate': 3.644986449864499e-05, 'epoch': 1.27}\n",
      "{'loss': 18.8368, 'grad_norm': 431798222848.0, 'learning_rate': 3.6382113821138216e-05, 'epoch': 1.27}\n",
      "{'loss': 18.4242, 'grad_norm': 1105604116480.0, 'learning_rate': 3.6314363143631436e-05, 'epoch': 1.28}\n",
      "{'loss': 18.35, 'grad_norm': 1770580344832.0, 'learning_rate': 3.624661246612466e-05, 'epoch': 1.28}\n",
      "{'loss': 18.1276, 'grad_norm': 3195461435392.0, 'learning_rate': 3.617886178861789e-05, 'epoch': 1.29}\n",
      "{'loss': 18.0671, 'grad_norm': 2830594998272.0, 'learning_rate': 3.611111111111111e-05, 'epoch': 1.29}\n",
      "{'loss': 17.9687, 'grad_norm': 2622787944448.0, 'learning_rate': 3.6043360433604336e-05, 'epoch': 1.3}\n",
      "{'loss': 17.932, 'grad_norm': 1144161173504.0, 'learning_rate': 3.597560975609756e-05, 'epoch': 1.3}\n",
      "{'loss': 18.1282, 'grad_norm': 306389647360.0, 'learning_rate': 3.590785907859079e-05, 'epoch': 1.31}\n",
      "{'loss': 17.8974, 'grad_norm': 100144996352.0, 'learning_rate': 3.584010840108401e-05, 'epoch': 1.31}\n",
      "{'loss': 18.0948, 'grad_norm': 925923213312.0, 'learning_rate': 3.577235772357724e-05, 'epoch': 1.32}\n",
      "{'loss': 17.7771, 'grad_norm': 1444680564736.0, 'learning_rate': 3.5704607046070464e-05, 'epoch': 1.32}\n",
      "{'loss': 17.8748, 'grad_norm': 860619997184.0, 'learning_rate': 3.5636856368563684e-05, 'epoch': 1.33}\n",
      "{'loss': 18.2475, 'grad_norm': 585955540992.0, 'learning_rate': 3.556910569105692e-05, 'epoch': 1.34}\n",
      "{'loss': 17.9908, 'grad_norm': 220005400576.0, 'learning_rate': 3.550135501355014e-05, 'epoch': 1.34}\n",
      "{'loss': 18.1222, 'grad_norm': 656270426112.0, 'learning_rate': 3.5433604336043364e-05, 'epoch': 1.35}\n",
      "{'loss': 18.6338, 'grad_norm': 1430937010176.0, 'learning_rate': 3.5365853658536584e-05, 'epoch': 1.35}\n",
      "{'loss': 20.2531, 'grad_norm': 2105903939584.0, 'learning_rate': 3.529810298102981e-05, 'epoch': 1.36}\n",
      "{'loss': 21.1071, 'grad_norm': 2872198037504.0, 'learning_rate': 3.523035230352303e-05, 'epoch': 1.36}\n",
      "{'loss': 19.8125, 'grad_norm': 887001907200.0, 'learning_rate': 3.5162601626016265e-05, 'epoch': 1.37}\n",
      "{'loss': 18.6917, 'grad_norm': 8185547063296.0, 'learning_rate': 3.509485094850949e-05, 'epoch': 1.37}\n",
      "{'loss': 19.4711, 'grad_norm': 3790352678912.0, 'learning_rate': 3.502710027100271e-05, 'epoch': 1.38}\n",
      "{'loss': 21.3878, 'grad_norm': 15008552452096.0, 'learning_rate': 3.495934959349594e-05, 'epoch': 1.38}\n",
      "{'loss': 20.5561, 'grad_norm': 2757032411136.0, 'learning_rate': 3.489159891598916e-05, 'epoch': 1.39}\n",
      "{'loss': 21.683, 'grad_norm': 1840840966144.0, 'learning_rate': 3.4823848238482385e-05, 'epoch': 1.39}\n",
      "{'loss': 21.175, 'grad_norm': 10241360003072.0, 'learning_rate': 3.475609756097561e-05, 'epoch': 1.4}\n",
      "{'loss': 21.9258, 'grad_norm': 973945176064.0, 'learning_rate': 3.468834688346884e-05, 'epoch': 1.4}\n",
      "{'loss': 20.9873, 'grad_norm': 945607999488.0, 'learning_rate': 3.4620596205962066e-05, 'epoch': 1.41}\n",
      "{'loss': 21.234, 'grad_norm': 1435672641536.0, 'learning_rate': 3.4552845528455286e-05, 'epoch': 1.41}\n",
      "{'loss': 22.3267, 'grad_norm': 1706754834432.0, 'learning_rate': 3.448509485094851e-05, 'epoch': 1.42}\n",
      "{'loss': 21.9594, 'grad_norm': 169487056896.0, 'learning_rate': 3.441734417344173e-05, 'epoch': 1.42}\n",
      "{'loss': 21.579, 'grad_norm': 157360799744.0, 'learning_rate': 3.434959349593496e-05, 'epoch': 1.43}\n",
      "{'loss': 21.8718, 'grad_norm': 339999129600.0, 'learning_rate': 3.4281842818428186e-05, 'epoch': 1.43}\n",
      "{'loss': 21.422, 'grad_norm': 464811524096.0, 'learning_rate': 3.421409214092141e-05, 'epoch': 1.44}\n",
      "{'loss': 21.4576, 'grad_norm': 867960619008.0, 'learning_rate': 3.414634146341464e-05, 'epoch': 1.44}\n",
      "{'loss': 23.0271, 'grad_norm': 453257625600.0, 'learning_rate': 3.407859078590786e-05, 'epoch': 1.45}\n",
      "{'loss': 22.3175, 'grad_norm': 3813716525056.0, 'learning_rate': 3.401084010840109e-05, 'epoch': 1.45}\n",
      "{'loss': 22.0553, 'grad_norm': 670889410560.0, 'learning_rate': 3.394308943089431e-05, 'epoch': 1.46}\n",
      "{'loss': 21.8194, 'grad_norm': 1471493701632.0, 'learning_rate': 3.3875338753387534e-05, 'epoch': 1.46}\n",
      "{'loss': 21.9345, 'grad_norm': 652956008448.0, 'learning_rate': 3.380758807588076e-05, 'epoch': 1.47}\n",
      "{'loss': 21.3851, 'grad_norm': 1184720617472.0, 'learning_rate': 3.373983739837399e-05, 'epoch': 1.47}\n",
      "{'loss': 22.3386, 'grad_norm': 2971808563200.0, 'learning_rate': 3.3672086720867214e-05, 'epoch': 1.48}\n",
      "{'loss': 26.3217, 'grad_norm': 534376775680.0, 'learning_rate': 3.3604336043360434e-05, 'epoch': 1.48}\n",
      "{'loss': 24.8647, 'grad_norm': 1104395501568.0, 'learning_rate': 3.353658536585366e-05, 'epoch': 1.49}\n",
      "{'loss': 23.6851, 'grad_norm': 267201921024.0, 'learning_rate': 3.346883468834688e-05, 'epoch': 1.49}\n",
      "{'loss': 23.448, 'grad_norm': 597558624256.0, 'learning_rate': 3.340108401084011e-05, 'epoch': 1.5}\n",
      "{'loss': 23.4121, 'grad_norm': 535926865920.0, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.5}\n",
      "{'loss': 22.2441, 'grad_norm': 358167248896.0, 'learning_rate': 3.326558265582656e-05, 'epoch': 1.51}\n",
      "{'loss': 22.1164, 'grad_norm': 361608413184.0, 'learning_rate': 3.319783197831978e-05, 'epoch': 1.51}\n",
      "{'loss': 21.9838, 'grad_norm': 2777853198336.0, 'learning_rate': 3.313008130081301e-05, 'epoch': 1.52}\n",
      "{'loss': 21.9649, 'grad_norm': 459722883072.0, 'learning_rate': 3.3062330623306235e-05, 'epoch': 1.52}\n",
      "{'loss': 21.075, 'grad_norm': 951714381824.0, 'learning_rate': 3.2994579945799456e-05, 'epoch': 1.53}\n",
      "{'loss': 19.7691, 'grad_norm': 1778393022464.0, 'learning_rate': 3.292682926829269e-05, 'epoch': 1.53}\n",
      "{'loss': 19.9184, 'grad_norm': 1009156358144.0, 'learning_rate': 3.285907859078591e-05, 'epoch': 1.54}\n",
      "{'loss': 21.0762, 'grad_norm': 1106550325248.0, 'learning_rate': 3.2791327913279136e-05, 'epoch': 1.54}\n",
      "{'loss': 21.2322, 'grad_norm': 544789266432.0, 'learning_rate': 3.2723577235772356e-05, 'epoch': 1.55}\n",
      "{'loss': 20.3065, 'grad_norm': 9216869793792.0, 'learning_rate': 3.265582655826558e-05, 'epoch': 1.55}\n",
      "{'loss': 18.91, 'grad_norm': 2418690490368.0, 'learning_rate': 3.258807588075881e-05, 'epoch': 1.56}\n",
      "{'loss': 17.9563, 'grad_norm': 4253157949440.0, 'learning_rate': 3.2520325203252037e-05, 'epoch': 1.56}\n",
      "{'loss': 18.3921, 'grad_norm': 19008787054592.0, 'learning_rate': 3.245257452574526e-05, 'epoch': 1.57}\n",
      "{'loss': 18.6822, 'grad_norm': 248447953272832.0, 'learning_rate': 3.2384823848238483e-05, 'epoch': 1.57}\n",
      "{'loss': 19.1584, 'grad_norm': 295822113636352.0, 'learning_rate': 3.231707317073171e-05, 'epoch': 1.58}\n",
      "{'loss': 20.7331, 'grad_norm': 263073608761344.0, 'learning_rate': 3.224932249322493e-05, 'epoch': 1.58}\n",
      "{'loss': 20.6206, 'grad_norm': 87955402129408.0, 'learning_rate': 3.218157181571816e-05, 'epoch': 1.59}\n",
      "{'loss': 20.267, 'grad_norm': 80596688699392.0, 'learning_rate': 3.2113821138211384e-05, 'epoch': 1.59}\n",
      "{'loss': 24.0729, 'grad_norm': 18068402176.0, 'learning_rate': 3.204607046070461e-05, 'epoch': 1.6}\n",
      "{'loss': 26.3978, 'grad_norm': 950807872.0, 'learning_rate': 3.197831978319784e-05, 'epoch': 1.6}\n",
      "{'loss': 25.5675, 'grad_norm': 165641392.0, 'learning_rate': 3.191056910569106e-05, 'epoch': 1.61}\n",
      "{'loss': 24.9837, 'grad_norm': 19930598.0, 'learning_rate': 3.1842818428184285e-05, 'epoch': 1.61}\n",
      "{'loss': 24.2398, 'grad_norm': 235874064.0, 'learning_rate': 3.1775067750677505e-05, 'epoch': 1.62}\n",
      "{'loss': 23.6457, 'grad_norm': 1821727232.0, 'learning_rate': 3.170731707317073e-05, 'epoch': 1.62}\n",
      "{'loss': 23.653, 'grad_norm': 46339512.0, 'learning_rate': 3.163956639566396e-05, 'epoch': 1.63}\n",
      "{'loss': 23.5903, 'grad_norm': 79780296.0, 'learning_rate': 3.1571815718157185e-05, 'epoch': 1.63}\n",
      "{'loss': 23.0334, 'grad_norm': 60629668.0, 'learning_rate': 3.150406504065041e-05, 'epoch': 1.64}\n",
      "{'loss': 22.1437, 'grad_norm': 68341432.0, 'learning_rate': 3.143631436314363e-05, 'epoch': 1.64}\n",
      "{'loss': 20.2575, 'grad_norm': 125885320.0, 'learning_rate': 3.136856368563686e-05, 'epoch': 1.65}\n",
      "{'loss': 19.888, 'grad_norm': 20276966.0, 'learning_rate': 3.130081300813008e-05, 'epoch': 1.65}\n",
      "{'loss': 18.5688, 'grad_norm': 14684254.0, 'learning_rate': 3.1233062330623306e-05, 'epoch': 1.66}\n",
      "{'loss': 17.3053, 'grad_norm': 2288360.0, 'learning_rate': 3.116531165311653e-05, 'epoch': 1.66}\n",
      "{'loss': 17.6468, 'grad_norm': 157548768.0, 'learning_rate': 3.109756097560976e-05, 'epoch': 1.67}\n",
      "{'loss': 19.8525, 'grad_norm': 205715632.0, 'learning_rate': 3.1029810298102986e-05, 'epoch': 1.68}\n",
      "{'loss': 19.9957, 'grad_norm': 141263632.0, 'learning_rate': 3.0962059620596206e-05, 'epoch': 1.68}\n",
      "{'loss': 19.241, 'grad_norm': 60341504.0, 'learning_rate': 3.089430894308943e-05, 'epoch': 1.69}\n",
      "{'loss': 19.7636, 'grad_norm': 61049168.0, 'learning_rate': 3.082655826558265e-05, 'epoch': 1.69}\n",
      "{'loss': 19.2764, 'grad_norm': 1476880896.0, 'learning_rate': 3.075880758807588e-05, 'epoch': 1.7}\n",
      "{'loss': 19.1805, 'grad_norm': 85767045120.0, 'learning_rate': 3.069105691056911e-05, 'epoch': 1.7}\n",
      "{'loss': 18.9811, 'grad_norm': 184384454656.0, 'learning_rate': 3.0623306233062334e-05, 'epoch': 1.71}\n",
      "{'loss': 18.7685, 'grad_norm': 524894273536.0, 'learning_rate': 3.055555555555556e-05, 'epoch': 1.71}\n",
      "{'loss': 19.3018, 'grad_norm': 512390201344.0, 'learning_rate': 3.048780487804878e-05, 'epoch': 1.72}\n",
      "{'loss': 19.1191, 'grad_norm': 3484454748160.0, 'learning_rate': 3.0420054200542007e-05, 'epoch': 1.72}\n",
      "{'loss': 19.0245, 'grad_norm': 606360502272.0, 'learning_rate': 3.035230352303523e-05, 'epoch': 1.73}\n",
      "{'loss': 18.3126, 'grad_norm': 39787098112.0, 'learning_rate': 3.0284552845528458e-05, 'epoch': 1.73}\n",
      "{'loss': 17.4039, 'grad_norm': 744689827840.0, 'learning_rate': 3.021680216802168e-05, 'epoch': 1.74}\n",
      "{'loss': 16.7225, 'grad_norm': 6932506624.0, 'learning_rate': 3.0149051490514908e-05, 'epoch': 1.74}\n",
      "{'loss': 16.1606, 'grad_norm': 324520512.0, 'learning_rate': 3.0081300813008135e-05, 'epoch': 1.75}\n",
      "{'loss': 16.0886, 'grad_norm': 55360472.0, 'learning_rate': 3.0013550135501355e-05, 'epoch': 1.75}\n",
      "{'loss': 16.4672, 'grad_norm': 48651228.0, 'learning_rate': 2.9945799457994585e-05, 'epoch': 1.76}\n",
      "{'loss': 16.4823, 'grad_norm': 128772224.0, 'learning_rate': 2.9878048780487805e-05, 'epoch': 1.76}\n",
      "{'loss': 16.6132, 'grad_norm': 86808376.0, 'learning_rate': 2.9810298102981032e-05, 'epoch': 1.77}\n",
      "{'loss': 16.0538, 'grad_norm': 53531496.0, 'learning_rate': 2.9742547425474255e-05, 'epoch': 1.77}\n",
      "{'loss': 15.0753, 'grad_norm': 10099881.0, 'learning_rate': 2.9674796747967482e-05, 'epoch': 1.78}\n",
      "{'loss': 15.6431, 'grad_norm': 59187184.0, 'learning_rate': 2.9607046070460702e-05, 'epoch': 1.78}\n",
      "{'loss': 15.5508, 'grad_norm': 296758688.0, 'learning_rate': 2.9539295392953932e-05, 'epoch': 1.79}\n",
      "{'loss': 17.3782, 'grad_norm': 208347424.0, 'learning_rate': 2.947154471544716e-05, 'epoch': 1.79}\n",
      "{'loss': 18.4829, 'grad_norm': 4346114560.0, 'learning_rate': 2.940379403794038e-05, 'epoch': 1.8}\n",
      "{'loss': 24.0805, 'grad_norm': 199826816.0, 'learning_rate': 2.9336043360433606e-05, 'epoch': 1.8}\n",
      "{'loss': 25.8323, 'grad_norm': 307915520.0, 'learning_rate': 2.926829268292683e-05, 'epoch': 1.81}\n",
      "{'loss': 26.4965, 'grad_norm': 45456124.0, 'learning_rate': 2.9200542005420056e-05, 'epoch': 1.81}\n",
      "{'loss': 27.4486, 'grad_norm': 15889907.0, 'learning_rate': 2.9132791327913276e-05, 'epoch': 1.82}\n",
      "{'loss': 29.1187, 'grad_norm': 5571529.5, 'learning_rate': 2.9065040650406507e-05, 'epoch': 1.82}\n",
      "{'loss': 23.3737, 'grad_norm': 10516292.0, 'learning_rate': 2.8997289972899733e-05, 'epoch': 1.83}\n",
      "{'loss': 17.0866, 'grad_norm': 11323860992.0, 'learning_rate': 2.8929539295392953e-05, 'epoch': 1.83}\n",
      "{'loss': 14.8587, 'grad_norm': 535966560.0, 'learning_rate': 2.886178861788618e-05, 'epoch': 1.84}\n",
      "{'loss': 13.9249, 'grad_norm': 2837331456.0, 'learning_rate': 2.8794037940379404e-05, 'epoch': 1.84}\n",
      "{'loss': 15.7731, 'grad_norm': 3470839040.0, 'learning_rate': 2.872628726287263e-05, 'epoch': 1.85}\n",
      "{'loss': 19.8448, 'grad_norm': 4645466112.0, 'learning_rate': 2.8658536585365854e-05, 'epoch': 1.85}\n",
      "{'loss': 21.4149, 'grad_norm': 1529509888.0, 'learning_rate': 2.859078590785908e-05, 'epoch': 1.86}\n",
      "{'loss': 21.3334, 'grad_norm': 8045150208.0, 'learning_rate': 2.8523035230352308e-05, 'epoch': 1.86}\n",
      "{'loss': 20.8738, 'grad_norm': 16985239552.0, 'learning_rate': 2.8455284552845528e-05, 'epoch': 1.87}\n",
      "{'loss': 20.787, 'grad_norm': 7357127680.0, 'learning_rate': 2.8387533875338758e-05, 'epoch': 1.87}\n",
      "{'loss': 21.1905, 'grad_norm': 3153627904.0, 'learning_rate': 2.8319783197831978e-05, 'epoch': 1.88}\n",
      "{'loss': 19.6865, 'grad_norm': 27551574016.0, 'learning_rate': 2.8252032520325205e-05, 'epoch': 1.88}\n",
      "{'loss': 21.1177, 'grad_norm': 3898904064.0, 'learning_rate': 2.8184281842818428e-05, 'epoch': 1.89}\n",
      "{'loss': 21.6371, 'grad_norm': 2483403008.0, 'learning_rate': 2.8116531165311655e-05, 'epoch': 1.89}\n",
      "{'loss': 21.1823, 'grad_norm': 465847584.0, 'learning_rate': 2.8048780487804882e-05, 'epoch': 1.9}\n",
      "{'loss': 21.5981, 'grad_norm': 2827060992.0, 'learning_rate': 2.7981029810298105e-05, 'epoch': 1.9}\n",
      "{'loss': 22.411, 'grad_norm': 433678496.0, 'learning_rate': 2.7913279132791332e-05, 'epoch': 1.91}\n",
      "{'loss': 23.0045, 'grad_norm': 619740992.0, 'learning_rate': 2.7845528455284552e-05, 'epoch': 1.91}\n",
      "{'loss': 21.7597, 'grad_norm': 1357616384.0, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.92}\n",
      "{'loss': 21.4575, 'grad_norm': 2995987968.0, 'learning_rate': 2.7710027100271003e-05, 'epoch': 1.92}\n",
      "{'loss': 23.1358, 'grad_norm': 479192448.0, 'learning_rate': 2.764227642276423e-05, 'epoch': 1.93}\n",
      "{'loss': 21.809, 'grad_norm': 1365003904.0, 'learning_rate': 2.7574525745257453e-05, 'epoch': 1.93}\n",
      "{'loss': 18.9009, 'grad_norm': 10190773248.0, 'learning_rate': 2.750677506775068e-05, 'epoch': 1.94}\n",
      "{'loss': 20.6774, 'grad_norm': 298375712.0, 'learning_rate': 2.7439024390243906e-05, 'epoch': 1.94}\n",
      "{'loss': 22.7145, 'grad_norm': 466462656.0, 'learning_rate': 2.7371273712737127e-05, 'epoch': 1.95}\n",
      "{'loss': 21.0167, 'grad_norm': 680701568.0, 'learning_rate': 2.7303523035230353e-05, 'epoch': 1.95}\n",
      "{'loss': 21.316, 'grad_norm': 202654832.0, 'learning_rate': 2.7235772357723577e-05, 'epoch': 1.96}\n",
      "{'loss': 23.0016, 'grad_norm': 745575616.0, 'learning_rate': 2.7168021680216804e-05, 'epoch': 1.96}\n",
      "{'loss': 22.2912, 'grad_norm': 574380416.0, 'learning_rate': 2.7100271002710027e-05, 'epoch': 1.97}\n",
      "{'loss': 22.172, 'grad_norm': 803751104.0, 'learning_rate': 2.7032520325203254e-05, 'epoch': 1.97}\n",
      "{'loss': 21.6656, 'grad_norm': 701847488.0, 'learning_rate': 2.696476964769648e-05, 'epoch': 1.98}\n",
      "{'loss': 21.29, 'grad_norm': 306991808.0, 'learning_rate': 2.68970189701897e-05, 'epoch': 1.98}\n",
      "{'loss': 21.3799, 'grad_norm': 759297536.0, 'learning_rate': 2.682926829268293e-05, 'epoch': 1.99}\n",
      "{'loss': 21.2557, 'grad_norm': 856378560.0, 'learning_rate': 2.676151761517615e-05, 'epoch': 1.99}\n",
      "{'loss': 21.6099, 'grad_norm': 649213056.0, 'learning_rate': 2.6693766937669378e-05, 'epoch': 2.0}\n",
      "{'loss': 21.9337, 'grad_norm': 716439936.0, 'learning_rate': 2.66260162601626e-05, 'epoch': 2.01}\n",
      "{'loss': 19.8648, 'grad_norm': 2196456704.0, 'learning_rate': 2.6558265582655828e-05, 'epoch': 2.01}\n",
      "{'loss': 17.5934, 'grad_norm': 1232725632.0, 'learning_rate': 2.6490514905149055e-05, 'epoch': 2.02}\n",
      "{'loss': 18.1549, 'grad_norm': 2097812096.0, 'learning_rate': 2.642276422764228e-05, 'epoch': 2.02}\n",
      "{'loss': 20.4337, 'grad_norm': 710962048.0, 'learning_rate': 2.6355013550135505e-05, 'epoch': 2.03}\n",
      "{'loss': 22.3249, 'grad_norm': 437888256.0, 'learning_rate': 2.6287262872628725e-05, 'epoch': 2.03}\n",
      "{'loss': 23.2792, 'grad_norm': 523802816.0, 'learning_rate': 2.6219512195121952e-05, 'epoch': 2.04}\n",
      "{'loss': 23.2209, 'grad_norm': 145303040.0, 'learning_rate': 2.6151761517615176e-05, 'epoch': 2.04}\n",
      "{'loss': 23.0761, 'grad_norm': 507937952.0, 'learning_rate': 2.6084010840108402e-05, 'epoch': 2.05}\n",
      "{'loss': 22.8082, 'grad_norm': 316589632.0, 'learning_rate': 2.601626016260163e-05, 'epoch': 2.05}\n",
      "{'loss': 21.7895, 'grad_norm': 812055168.0, 'learning_rate': 2.5948509485094853e-05, 'epoch': 2.06}\n",
      "{'loss': 22.1332, 'grad_norm': 1021702592.0, 'learning_rate': 2.588075880758808e-05, 'epoch': 2.06}\n",
      "{'loss': 22.7898, 'grad_norm': 1055638976.0, 'learning_rate': 2.58130081300813e-05, 'epoch': 2.07}\n",
      "{'loss': 22.618, 'grad_norm': 1158977792.0, 'learning_rate': 2.574525745257453e-05, 'epoch': 2.07}\n",
      "{'loss': 22.2181, 'grad_norm': 730088192.0, 'learning_rate': 2.567750677506775e-05, 'epoch': 2.08}\n",
      "{'loss': 22.413, 'grad_norm': 8626555904.0, 'learning_rate': 2.5609756097560977e-05, 'epoch': 2.08}\n",
      "{'loss': 22.2241, 'grad_norm': 2113314816.0, 'learning_rate': 2.55420054200542e-05, 'epoch': 2.09}\n",
      "{'loss': 21.8577, 'grad_norm': 1181578496.0, 'learning_rate': 2.5474254742547427e-05, 'epoch': 2.09}\n",
      "{'loss': 22.54, 'grad_norm': 1849042304.0, 'learning_rate': 2.5406504065040654e-05, 'epoch': 2.1}\n",
      "{'loss': 22.8497, 'grad_norm': 244148016.0, 'learning_rate': 2.5338753387533877e-05, 'epoch': 2.1}\n",
      "{'loss': 22.8156, 'grad_norm': 406847584.0, 'learning_rate': 2.5271002710027104e-05, 'epoch': 2.11}\n",
      "{'loss': 22.5017, 'grad_norm': 306337152.0, 'learning_rate': 2.5203252032520324e-05, 'epoch': 2.11}\n",
      "{'loss': 22.3657, 'grad_norm': 1240923008.0, 'learning_rate': 2.513550135501355e-05, 'epoch': 2.12}\n",
      "{'loss': 22.9504, 'grad_norm': 1951356288.0, 'learning_rate': 2.5067750677506774e-05, 'epoch': 2.12}\n",
      "{'loss': 23.6531, 'grad_norm': 122303264.0, 'learning_rate': 2.5e-05, 'epoch': 2.13}\n",
      "{'loss': 23.2108, 'grad_norm': 294727968.0, 'learning_rate': 2.4932249322493225e-05, 'epoch': 2.13}\n",
      "{'loss': 22.7853, 'grad_norm': 391052224.0, 'learning_rate': 2.486449864498645e-05, 'epoch': 2.14}\n",
      "{'loss': 22.4111, 'grad_norm': 756403648.0, 'learning_rate': 2.4796747967479675e-05, 'epoch': 2.14}\n",
      "{'loss': 21.2369, 'grad_norm': 19228336128.0, 'learning_rate': 2.4728997289972902e-05, 'epoch': 2.15}\n",
      "{'loss': 18.9952, 'grad_norm': 386600736.0, 'learning_rate': 2.4661246612466125e-05, 'epoch': 2.15}\n",
      "{'loss': 16.3742, 'grad_norm': 626811904.0, 'learning_rate': 2.4593495934959352e-05, 'epoch': 2.16}\n",
      "{'loss': 13.4675, 'grad_norm': 30628976.0, 'learning_rate': 2.4525745257452575e-05, 'epoch': 2.16}\n",
      "{'loss': 11.0325, 'grad_norm': 1811342.75, 'learning_rate': 2.44579945799458e-05, 'epoch': 2.17}\n",
      "{'loss': 11.6012, 'grad_norm': 3749077.25, 'learning_rate': 2.4390243902439026e-05, 'epoch': 2.17}\n",
      "{'loss': 11.9535, 'grad_norm': 4400600.0, 'learning_rate': 2.432249322493225e-05, 'epoch': 2.18}\n",
      "{'loss': 11.3643, 'grad_norm': 572811.9375, 'learning_rate': 2.4254742547425473e-05, 'epoch': 2.18}\n",
      "{'loss': 10.3075, 'grad_norm': 152956.25, 'learning_rate': 2.4186991869918703e-05, 'epoch': 2.19}\n",
      "{'loss': 8.8915, 'grad_norm': 87589.4609375, 'learning_rate': 2.4119241192411926e-05, 'epoch': 2.19}\n",
      "{'loss': 6.4387, 'grad_norm': 36484.3359375, 'learning_rate': 2.405149051490515e-05, 'epoch': 2.2}\n",
      "{'loss': 2.888, 'grad_norm': 36331.1171875, 'learning_rate': 2.3983739837398377e-05, 'epoch': 2.2}\n",
      "{'loss': 1.4392, 'grad_norm': 2176.80322265625, 'learning_rate': 2.39159891598916e-05, 'epoch': 2.21}\n",
      "{'loss': 1.2012, 'grad_norm': 12587.1708984375, 'learning_rate': 2.3848238482384823e-05, 'epoch': 2.21}\n",
      "{'loss': 1.122, 'grad_norm': 2230.457763671875, 'learning_rate': 2.378048780487805e-05, 'epoch': 2.22}\n",
      "{'loss': 1.0623, 'grad_norm': 9031.466796875, 'learning_rate': 2.3712737127371277e-05, 'epoch': 2.22}\n",
      "{'loss': 1.208, 'grad_norm': 874945.4375, 'learning_rate': 2.36449864498645e-05, 'epoch': 2.23}\n",
      "{'loss': 1.8226, 'grad_norm': 2696336.5, 'learning_rate': 2.3577235772357724e-05, 'epoch': 2.23}\n",
      "{'loss': 3.0007, 'grad_norm': 2361325.75, 'learning_rate': 2.350948509485095e-05, 'epoch': 2.24}\n",
      "{'loss': 3.3347, 'grad_norm': 1606971.875, 'learning_rate': 2.3441734417344174e-05, 'epoch': 2.24}\n",
      "{'loss': 2.8128, 'grad_norm': 1854044.0, 'learning_rate': 2.3373983739837398e-05, 'epoch': 2.25}\n",
      "{'loss': 2.1484, 'grad_norm': 1316949.75, 'learning_rate': 2.3306233062330625e-05, 'epoch': 2.25}\n",
      "{'loss': 1.7494, 'grad_norm': 91242760.0, 'learning_rate': 2.3238482384823848e-05, 'epoch': 2.26}\n",
      "{'loss': 1.8223, 'grad_norm': 9647389.0, 'learning_rate': 2.3170731707317075e-05, 'epoch': 2.26}\n",
      "{'loss': 1.8103, 'grad_norm': 1375994880.0, 'learning_rate': 2.31029810298103e-05, 'epoch': 2.27}\n",
      "{'loss': 1.6521, 'grad_norm': 54177212.0, 'learning_rate': 2.3035230352303525e-05, 'epoch': 2.27}\n",
      "{'loss': 1.7196, 'grad_norm': 3188332288.0, 'learning_rate': 2.296747967479675e-05, 'epoch': 2.28}\n",
      "{'loss': 1.6713, 'grad_norm': 102343896.0, 'learning_rate': 2.2899728997289975e-05, 'epoch': 2.28}\n",
      "{'loss': 1.6626, 'grad_norm': 138992352.0, 'learning_rate': 2.28319783197832e-05, 'epoch': 2.29}\n",
      "{'loss': 1.638, 'grad_norm': 170852528.0, 'learning_rate': 2.2764227642276422e-05, 'epoch': 2.29}\n",
      "{'loss': 1.7728, 'grad_norm': 47549712.0, 'learning_rate': 2.269647696476965e-05, 'epoch': 2.3}\n",
      "{'loss': 1.9949, 'grad_norm': 144360848.0, 'learning_rate': 2.2628726287262876e-05, 'epoch': 2.3}\n",
      "{'loss': 1.8424, 'grad_norm': 373946400.0, 'learning_rate': 2.25609756097561e-05, 'epoch': 2.31}\n",
      "{'loss': 1.6566, 'grad_norm': 885510144.0, 'learning_rate': 2.2493224932249323e-05, 'epoch': 2.31}\n",
      "{'loss': 1.9259, 'grad_norm': 57867120.0, 'learning_rate': 2.242547425474255e-05, 'epoch': 2.32}\n",
      "{'loss': 1.9483, 'grad_norm': 683344768.0, 'learning_rate': 2.2357723577235773e-05, 'epoch': 2.32}\n",
      "{'loss': 1.8736, 'grad_norm': 166094080.0, 'learning_rate': 2.2289972899728996e-05, 'epoch': 2.33}\n",
      "{'loss': 2.2016, 'grad_norm': 469367680.0, 'learning_rate': 2.2222222222222223e-05, 'epoch': 2.34}\n",
      "{'loss': 1.9875, 'grad_norm': 381293952.0, 'learning_rate': 2.215447154471545e-05, 'epoch': 2.34}\n",
      "{'loss': 2.2096, 'grad_norm': 56734312.0, 'learning_rate': 2.2086720867208674e-05, 'epoch': 2.35}\n",
      "{'loss': 2.2161, 'grad_norm': 156003504.0, 'learning_rate': 2.2018970189701897e-05, 'epoch': 2.35}\n",
      "{'loss': 2.0372, 'grad_norm': 561697152.0, 'learning_rate': 2.1951219512195124e-05, 'epoch': 2.36}\n",
      "{'loss': 2.3444, 'grad_norm': 321080960.0, 'learning_rate': 2.1883468834688347e-05, 'epoch': 2.36}\n",
      "{'loss': 2.5003, 'grad_norm': 152097472.0, 'learning_rate': 2.181571815718157e-05, 'epoch': 2.37}\n",
      "{'loss': 2.4736, 'grad_norm': 341671392.0, 'learning_rate': 2.1747967479674798e-05, 'epoch': 2.37}\n",
      "{'loss': 2.2684, 'grad_norm': 840904512.0, 'learning_rate': 2.1680216802168024e-05, 'epoch': 2.38}\n",
      "{'loss': 2.3724, 'grad_norm': 392946016.0, 'learning_rate': 2.1612466124661248e-05, 'epoch': 2.38}\n",
      "{'loss': 2.5842, 'grad_norm': 1616768384.0, 'learning_rate': 2.1544715447154475e-05, 'epoch': 2.39}\n",
      "{'loss': 2.0406, 'grad_norm': 258482384.0, 'learning_rate': 2.1476964769647698e-05, 'epoch': 2.39}\n",
      "{'loss': 1.9683, 'grad_norm': 3264399360.0, 'learning_rate': 2.140921409214092e-05, 'epoch': 2.4}\n",
      "{'loss': 1.8948, 'grad_norm': 3907193600.0, 'learning_rate': 2.134146341463415e-05, 'epoch': 2.4}\n",
      "{'loss': 1.7911, 'grad_norm': 20984264.0, 'learning_rate': 2.1273712737127372e-05, 'epoch': 2.41}\n",
      "{'loss': 1.4551, 'grad_norm': 46096480.0, 'learning_rate': 2.1205962059620595e-05, 'epoch': 2.41}\n",
      "{'loss': 1.3938, 'grad_norm': 2951882.5, 'learning_rate': 2.1138211382113822e-05, 'epoch': 2.42}\n",
      "{'loss': 1.2498, 'grad_norm': 239009.453125, 'learning_rate': 2.107046070460705e-05, 'epoch': 2.42}\n",
      "{'loss': 1.3588, 'grad_norm': 2186098.5, 'learning_rate': 2.1002710027100272e-05, 'epoch': 2.43}\n",
      "{'loss': 1.7809, 'grad_norm': 22686054.0, 'learning_rate': 2.0934959349593496e-05, 'epoch': 2.43}\n",
      "{'loss': 1.9585, 'grad_norm': 1691046528.0, 'learning_rate': 2.0867208672086723e-05, 'epoch': 2.44}\n",
      "{'loss': 2.7032, 'grad_norm': 40492072960.0, 'learning_rate': 2.0799457994579946e-05, 'epoch': 2.44}\n",
      "{'loss': 3.9425, 'grad_norm': 3038355968.0, 'learning_rate': 2.073170731707317e-05, 'epoch': 2.45}\n",
      "{'loss': 3.4964, 'grad_norm': 7298547712.0, 'learning_rate': 2.0663956639566396e-05, 'epoch': 2.45}\n",
      "{'loss': 3.9002, 'grad_norm': 2980257536.0, 'learning_rate': 2.0596205962059623e-05, 'epoch': 2.46}\n",
      "{'loss': 3.8036, 'grad_norm': 11543903232.0, 'learning_rate': 2.0528455284552847e-05, 'epoch': 2.46}\n",
      "{'loss': 3.4635, 'grad_norm': 6671660032.0, 'learning_rate': 2.046070460704607e-05, 'epoch': 2.47}\n",
      "{'loss': 3.2382, 'grad_norm': 16375246848.0, 'learning_rate': 2.0392953929539297e-05, 'epoch': 2.47}\n",
      "{'loss': 3.2986, 'grad_norm': 2859873280.0, 'learning_rate': 2.032520325203252e-05, 'epoch': 2.48}\n",
      "{'loss': 3.8493, 'grad_norm': 19893256192.0, 'learning_rate': 2.0257452574525744e-05, 'epoch': 2.48}\n",
      "{'loss': 3.8193, 'grad_norm': 15321450496.0, 'learning_rate': 2.018970189701897e-05, 'epoch': 2.49}\n",
      "{'loss': 3.6663, 'grad_norm': 41865306112.0, 'learning_rate': 2.0121951219512197e-05, 'epoch': 2.49}\n",
      "{'loss': 3.676, 'grad_norm': 48648949760.0, 'learning_rate': 2.005420054200542e-05, 'epoch': 2.5}\n",
      "{'loss': 3.8046, 'grad_norm': 9840313344.0, 'learning_rate': 1.9986449864498648e-05, 'epoch': 2.5}\n",
      "{'loss': 3.8628, 'grad_norm': 23999569920.0, 'learning_rate': 1.991869918699187e-05, 'epoch': 2.51}\n",
      "{'loss': 3.8176, 'grad_norm': 8241697792.0, 'learning_rate': 1.9850948509485095e-05, 'epoch': 2.51}\n",
      "{'loss': 3.6144, 'grad_norm': 8873864192.0, 'learning_rate': 1.978319783197832e-05, 'epoch': 2.52}\n",
      "{'loss': 3.5033, 'grad_norm': 1951995648.0, 'learning_rate': 1.9715447154471545e-05, 'epoch': 2.52}\n",
      "{'loss': 3.5296, 'grad_norm': 4317224960.0, 'learning_rate': 1.9647696476964768e-05, 'epoch': 2.53}\n",
      "{'loss': 3.9953, 'grad_norm': 6104462336.0, 'learning_rate': 1.9579945799457995e-05, 'epoch': 2.53}\n",
      "{'loss': 4.3896, 'grad_norm': 4690017280.0, 'learning_rate': 1.9512195121951222e-05, 'epoch': 2.54}\n",
      "{'loss': 4.9552, 'grad_norm': 15408346112.0, 'learning_rate': 1.9444444444444445e-05, 'epoch': 2.54}\n",
      "{'loss': 4.8231, 'grad_norm': 4579767296.0, 'learning_rate': 1.937669376693767e-05, 'epoch': 2.55}\n",
      "{'loss': 4.6508, 'grad_norm': 2878267392.0, 'learning_rate': 1.9308943089430896e-05, 'epoch': 2.55}\n",
      "{'loss': 4.4325, 'grad_norm': 6776662528.0, 'learning_rate': 1.924119241192412e-05, 'epoch': 2.56}\n",
      "{'loss': 3.8767, 'grad_norm': 2830633472.0, 'learning_rate': 1.9173441734417343e-05, 'epoch': 2.56}\n",
      "{'loss': 2.8407, 'grad_norm': 3590321152.0, 'learning_rate': 1.9105691056910573e-05, 'epoch': 2.57}\n",
      "{'loss': 3.0988, 'grad_norm': 2443140096.0, 'learning_rate': 1.9037940379403796e-05, 'epoch': 2.57}\n",
      "{'loss': 4.042, 'grad_norm': 6155327488.0, 'learning_rate': 1.897018970189702e-05, 'epoch': 2.58}\n",
      "{'loss': 4.6832, 'grad_norm': 73001992192.0, 'learning_rate': 1.8902439024390246e-05, 'epoch': 2.58}\n",
      "{'loss': 4.9079, 'grad_norm': 12160514048.0, 'learning_rate': 1.883468834688347e-05, 'epoch': 2.59}\n",
      "{'loss': 4.0913, 'grad_norm': 3153239552.0, 'learning_rate': 1.8766937669376693e-05, 'epoch': 2.59}\n",
      "{'loss': 3.6472, 'grad_norm': 8797481984.0, 'learning_rate': 1.869918699186992e-05, 'epoch': 2.6}\n",
      "{'loss': 3.8455, 'grad_norm': 1655272320.0, 'learning_rate': 1.8631436314363144e-05, 'epoch': 2.6}\n",
      "{'loss': 4.3758, 'grad_norm': 12939965440.0, 'learning_rate': 1.856368563685637e-05, 'epoch': 2.61}\n",
      "{'loss': 4.2859, 'grad_norm': 2001590528.0, 'learning_rate': 1.8495934959349594e-05, 'epoch': 2.61}\n",
      "{'loss': 4.6951, 'grad_norm': 7775290368.0, 'learning_rate': 1.842818428184282e-05, 'epoch': 2.62}\n",
      "{'loss': 4.8256, 'grad_norm': 5223041536.0, 'learning_rate': 1.8360433604336044e-05, 'epoch': 2.62}\n",
      "{'loss': 4.2213, 'grad_norm': 9034443776.0, 'learning_rate': 1.8292682926829268e-05, 'epoch': 2.63}\n",
      "{'loss': 3.6273, 'grad_norm': 1865232896.0, 'learning_rate': 1.8224932249322494e-05, 'epoch': 2.63}\n",
      "{'loss': 3.5201, 'grad_norm': 798017984.0, 'learning_rate': 1.8157181571815718e-05, 'epoch': 2.64}\n",
      "{'loss': 3.0685, 'grad_norm': 441727840.0, 'learning_rate': 1.8089430894308945e-05, 'epoch': 2.64}\n",
      "{'loss': 2.575, 'grad_norm': 3563266304.0, 'learning_rate': 1.8021680216802168e-05, 'epoch': 2.65}\n",
      "{'loss': 2.6492, 'grad_norm': 20933830656.0, 'learning_rate': 1.7953929539295395e-05, 'epoch': 2.65}\n",
      "{'loss': 2.7192, 'grad_norm': 6830013952.0, 'learning_rate': 1.788617886178862e-05, 'epoch': 2.66}\n",
      "{'loss': 2.8775, 'grad_norm': 15234058240.0, 'learning_rate': 1.7818428184281842e-05, 'epoch': 2.66}\n",
      "{'loss': 3.3418, 'grad_norm': 5849275904.0, 'learning_rate': 1.775067750677507e-05, 'epoch': 2.67}\n",
      "{'loss': 3.823, 'grad_norm': 18339426304.0, 'learning_rate': 1.7682926829268292e-05, 'epoch': 2.68}\n",
      "{'loss': 3.3412, 'grad_norm': 88030994432.0, 'learning_rate': 1.7615176151761516e-05, 'epoch': 2.68}\n",
      "{'loss': 3.293, 'grad_norm': 26098792448.0, 'learning_rate': 1.7547425474254746e-05, 'epoch': 2.69}\n",
      "{'loss': 2.8337, 'grad_norm': 6299639296.0, 'learning_rate': 1.747967479674797e-05, 'epoch': 2.69}\n",
      "{'loss': 3.0587, 'grad_norm': 4144685056.0, 'learning_rate': 1.7411924119241193e-05, 'epoch': 2.7}\n",
      "{'loss': 3.005, 'grad_norm': 5602070016.0, 'learning_rate': 1.734417344173442e-05, 'epoch': 2.7}\n",
      "{'loss': 3.5034, 'grad_norm': 48789655552.0, 'learning_rate': 1.7276422764227643e-05, 'epoch': 2.71}\n",
      "{'loss': 3.5276, 'grad_norm': 19024209920.0, 'learning_rate': 1.7208672086720866e-05, 'epoch': 2.71}\n",
      "{'loss': 3.4821, 'grad_norm': 5765599232.0, 'learning_rate': 1.7140921409214093e-05, 'epoch': 2.72}\n",
      "{'loss': 2.9788, 'grad_norm': 50331844608.0, 'learning_rate': 1.707317073170732e-05, 'epoch': 2.72}\n",
      "{'loss': 3.313, 'grad_norm': 12261243904.0, 'learning_rate': 1.7005420054200543e-05, 'epoch': 2.73}\n",
      "{'loss': 3.7286, 'grad_norm': 14866931712.0, 'learning_rate': 1.6937669376693767e-05, 'epoch': 2.73}\n",
      "{'loss': 3.5984, 'grad_norm': 3153368832.0, 'learning_rate': 1.6869918699186994e-05, 'epoch': 2.74}\n",
      "{'loss': 3.4427, 'grad_norm': 165629968384.0, 'learning_rate': 1.6802168021680217e-05, 'epoch': 2.74}\n",
      "{'loss': 3.3732, 'grad_norm': 76617859072.0, 'learning_rate': 1.673441734417344e-05, 'epoch': 2.75}\n",
      "{'loss': 4.0602, 'grad_norm': 30643896320.0, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.75}\n",
      "{'loss': 4.1591, 'grad_norm': 29867909120.0, 'learning_rate': 1.659891598915989e-05, 'epoch': 2.76}\n",
      "{'loss': 4.6953, 'grad_norm': 5730653184.0, 'learning_rate': 1.6531165311653118e-05, 'epoch': 2.76}\n",
      "{'loss': 4.3972, 'grad_norm': 1591387136.0, 'learning_rate': 1.6463414634146345e-05, 'epoch': 2.77}\n",
      "{'loss': 3.9124, 'grad_norm': 16610056192.0, 'learning_rate': 1.6395663956639568e-05, 'epoch': 2.77}\n",
      "{'loss': 4.0627, 'grad_norm': 20079978496.0, 'learning_rate': 1.632791327913279e-05, 'epoch': 2.78}\n",
      "{'loss': 3.9284, 'grad_norm': 7182034432.0, 'learning_rate': 1.6260162601626018e-05, 'epoch': 2.78}\n",
      "{'loss': 3.6234, 'grad_norm': 53683273728.0, 'learning_rate': 1.6192411924119242e-05, 'epoch': 2.79}\n",
      "{'loss': 4.001, 'grad_norm': 5189142528.0, 'learning_rate': 1.6124661246612465e-05, 'epoch': 2.79}\n",
      "{'loss': 4.3445, 'grad_norm': 512423392.0, 'learning_rate': 1.6056910569105692e-05, 'epoch': 2.8}\n",
      "{'loss': 3.9098, 'grad_norm': 3607855872.0, 'learning_rate': 1.598915989159892e-05, 'epoch': 2.8}\n",
      "{'loss': 4.5563, 'grad_norm': 55456071680.0, 'learning_rate': 1.5921409214092142e-05, 'epoch': 2.81}\n",
      "{'loss': 5.7246, 'grad_norm': 25385650176.0, 'learning_rate': 1.5853658536585366e-05, 'epoch': 2.81}\n",
      "{'loss': 7.3572, 'grad_norm': 50351050752.0, 'learning_rate': 1.5785907859078593e-05, 'epoch': 2.82}\n",
      "{'loss': 8.1083, 'grad_norm': 6097897984.0, 'learning_rate': 1.5718157181571816e-05, 'epoch': 2.82}\n",
      "{'loss': 8.4744, 'grad_norm': 19017152512.0, 'learning_rate': 1.565040650406504e-05, 'epoch': 2.83}\n",
      "{'loss': 8.4043, 'grad_norm': 51051479040.0, 'learning_rate': 1.5582655826558266e-05, 'epoch': 2.83}\n",
      "{'loss': 8.289, 'grad_norm': 25856376832.0, 'learning_rate': 1.5514905149051493e-05, 'epoch': 2.84}\n",
      "{'loss': 8.5842, 'grad_norm': 57155305472.0, 'learning_rate': 1.5447154471544717e-05, 'epoch': 2.84}\n",
      "{'loss': 8.8474, 'grad_norm': 67371851776.0, 'learning_rate': 1.537940379403794e-05, 'epoch': 2.85}\n",
      "{'loss': 9.34, 'grad_norm': 25623070720.0, 'learning_rate': 1.5311653116531167e-05, 'epoch': 2.85}\n",
      "{'loss': 9.1193, 'grad_norm': 119181893632.0, 'learning_rate': 1.524390243902439e-05, 'epoch': 2.86}\n",
      "{'loss': 9.953, 'grad_norm': 71038205952.0, 'learning_rate': 1.5176151761517615e-05, 'epoch': 2.86}\n",
      "{'loss': 9.8525, 'grad_norm': 65697832960.0, 'learning_rate': 1.510840108401084e-05, 'epoch': 2.87}\n",
      "{'loss': 9.7521, 'grad_norm': 234575167488.0, 'learning_rate': 1.5040650406504067e-05, 'epoch': 2.87}\n",
      "{'loss': 9.3107, 'grad_norm': 227196534784.0, 'learning_rate': 1.4972899728997292e-05, 'epoch': 2.88}\n",
      "{'loss': 8.2688, 'grad_norm': 11333072896.0, 'learning_rate': 1.4905149051490516e-05, 'epoch': 2.88}\n",
      "{'loss': 6.8947, 'grad_norm': 6277117440.0, 'learning_rate': 1.4837398373983741e-05, 'epoch': 2.89}\n",
      "{'loss': 6.0651, 'grad_norm': 6170491392.0, 'learning_rate': 1.4769647696476966e-05, 'epoch': 2.89}\n",
      "{'loss': 5.9574, 'grad_norm': 9747661824.0, 'learning_rate': 1.470189701897019e-05, 'epoch': 2.9}\n",
      "{'loss': 4.6101, 'grad_norm': 4684259328.0, 'learning_rate': 1.4634146341463415e-05, 'epoch': 2.9}\n",
      "{'loss': 3.9258, 'grad_norm': 1068834944.0, 'learning_rate': 1.4566395663956638e-05, 'epoch': 2.91}\n",
      "{'loss': 4.0103, 'grad_norm': 4354485760.0, 'learning_rate': 1.4498644986449867e-05, 'epoch': 2.91}\n",
      "{'loss': 4.0779, 'grad_norm': 1106035456.0, 'learning_rate': 1.443089430894309e-05, 'epoch': 2.92}\n",
      "{'loss': 4.2877, 'grad_norm': 524497952.0, 'learning_rate': 1.4363143631436315e-05, 'epoch': 2.92}\n",
      "{'loss': 4.5424, 'grad_norm': 925653632.0, 'learning_rate': 1.429539295392954e-05, 'epoch': 2.93}\n",
      "{'loss': 4.7455, 'grad_norm': 15160150016.0, 'learning_rate': 1.4227642276422764e-05, 'epoch': 2.93}\n",
      "{'loss': 4.7992, 'grad_norm': 2437720832.0, 'learning_rate': 1.4159891598915989e-05, 'epoch': 2.94}\n",
      "{'loss': 4.5343, 'grad_norm': 3227604480.0, 'learning_rate': 1.4092140921409214e-05, 'epoch': 2.94}\n",
      "{'loss': 5.0032, 'grad_norm': 16661595136.0, 'learning_rate': 1.4024390243902441e-05, 'epoch': 2.95}\n",
      "{'loss': 5.0713, 'grad_norm': 5139214848.0, 'learning_rate': 1.3956639566395666e-05, 'epoch': 2.95}\n",
      "{'loss': 4.8189, 'grad_norm': 18875856896.0, 'learning_rate': 1.388888888888889e-05, 'epoch': 2.96}\n",
      "{'loss': 5.0122, 'grad_norm': 20981891072.0, 'learning_rate': 1.3821138211382115e-05, 'epoch': 2.96}\n",
      "{'loss': 5.4479, 'grad_norm': 24405438464.0, 'learning_rate': 1.375338753387534e-05, 'epoch': 2.97}\n",
      "{'loss': 5.1376, 'grad_norm': 13134484480.0, 'learning_rate': 1.3685636856368563e-05, 'epoch': 2.97}\n",
      "{'loss': 4.5948, 'grad_norm': 5712531968.0, 'learning_rate': 1.3617886178861788e-05, 'epoch': 2.98}\n",
      "{'loss': 3.8932, 'grad_norm': 690715712.0, 'learning_rate': 1.3550135501355014e-05, 'epoch': 2.98}\n",
      "{'loss': 3.7002, 'grad_norm': 1304449408.0, 'learning_rate': 1.348238482384824e-05, 'epoch': 2.99}\n",
      "{'loss': 3.601, 'grad_norm': 3027765760.0, 'learning_rate': 1.3414634146341466e-05, 'epoch': 2.99}\n",
      "{'loss': 3.8555, 'grad_norm': 729974208.0, 'learning_rate': 1.3346883468834689e-05, 'epoch': 3.0}\n",
      "{'loss': 4.0538, 'grad_norm': 84508712960.0, 'learning_rate': 1.3279132791327914e-05, 'epoch': 3.01}\n",
      "{'loss': 4.4065, 'grad_norm': 20884350976.0, 'learning_rate': 1.321138211382114e-05, 'epoch': 3.01}\n",
      "{'loss': 4.2008, 'grad_norm': 2565369344.0, 'learning_rate': 1.3143631436314363e-05, 'epoch': 3.02}\n",
      "{'loss': 4.1943, 'grad_norm': 11132817408.0, 'learning_rate': 1.3075880758807588e-05, 'epoch': 3.02}\n",
      "{'loss': 4.04, 'grad_norm': 1241408896.0, 'learning_rate': 1.3008130081300815e-05, 'epoch': 3.03}\n",
      "{'loss': 4.4574, 'grad_norm': 7253284352.0, 'learning_rate': 1.294037940379404e-05, 'epoch': 3.03}\n",
      "{'loss': 3.9992, 'grad_norm': 3641208832.0, 'learning_rate': 1.2872628726287265e-05, 'epoch': 3.04}\n",
      "{'loss': 4.0341, 'grad_norm': 7395150336.0, 'learning_rate': 1.2804878048780488e-05, 'epoch': 3.04}\n",
      "{'loss': 4.4957, 'grad_norm': 7122224128.0, 'learning_rate': 1.2737127371273713e-05, 'epoch': 3.05}\n",
      "{'loss': 4.461, 'grad_norm': 53609222144.0, 'learning_rate': 1.2669376693766939e-05, 'epoch': 3.05}\n",
      "{'loss': 4.3695, 'grad_norm': 35177242624.0, 'learning_rate': 1.2601626016260162e-05, 'epoch': 3.06}\n",
      "{'loss': 4.0545, 'grad_norm': 85963505664.0, 'learning_rate': 1.2533875338753387e-05, 'epoch': 3.06}\n",
      "{'loss': 3.9341, 'grad_norm': 130416721920.0, 'learning_rate': 1.2466124661246612e-05, 'epoch': 3.07}\n",
      "{'loss': 3.9803, 'grad_norm': 104612757504.0, 'learning_rate': 1.2398373983739837e-05, 'epoch': 3.07}\n",
      "{'loss': 4.1342, 'grad_norm': 26648506368.0, 'learning_rate': 1.2330623306233063e-05, 'epoch': 3.08}\n",
      "{'loss': 4.522, 'grad_norm': 40421363712.0, 'learning_rate': 1.2262872628726288e-05, 'epoch': 3.08}\n",
      "{'loss': 5.0409, 'grad_norm': 76808183808.0, 'learning_rate': 1.2195121951219513e-05, 'epoch': 3.09}\n",
      "{'loss': 4.7953, 'grad_norm': 75482046464.0, 'learning_rate': 1.2127371273712736e-05, 'epoch': 3.09}\n",
      "{'loss': 4.8628, 'grad_norm': 18531764224.0, 'learning_rate': 1.2059620596205963e-05, 'epoch': 3.1}\n",
      "{'loss': 4.643, 'grad_norm': 37858062336.0, 'learning_rate': 1.1991869918699188e-05, 'epoch': 3.1}\n",
      "{'loss': 4.8124, 'grad_norm': 21988321280.0, 'learning_rate': 1.1924119241192412e-05, 'epoch': 3.11}\n",
      "{'loss': 4.675, 'grad_norm': 12354568192.0, 'learning_rate': 1.1856368563685639e-05, 'epoch': 3.11}\n",
      "{'loss': 4.7, 'grad_norm': 5335958528.0, 'learning_rate': 1.1788617886178862e-05, 'epoch': 3.12}\n",
      "{'loss': 4.231, 'grad_norm': 19649767424.0, 'learning_rate': 1.1720867208672087e-05, 'epoch': 3.12}\n",
      "{'loss': 4.4961, 'grad_norm': 5167598080.0, 'learning_rate': 1.1653116531165312e-05, 'epoch': 3.13}\n",
      "{'loss': 4.3132, 'grad_norm': 1258121344.0, 'learning_rate': 1.1585365853658537e-05, 'epoch': 3.13}\n",
      "{'loss': 4.6891, 'grad_norm': 3331897344.0, 'learning_rate': 1.1517615176151763e-05, 'epoch': 3.14}\n",
      "{'loss': 5.2491, 'grad_norm': 3853014784.0, 'learning_rate': 1.1449864498644988e-05, 'epoch': 3.14}\n",
      "{'loss': 5.6043, 'grad_norm': 48386596864.0, 'learning_rate': 1.1382113821138211e-05, 'epoch': 3.15}\n",
      "{'loss': 6.4194, 'grad_norm': 90902249472.0, 'learning_rate': 1.1314363143631438e-05, 'epoch': 3.15}\n",
      "{'loss': 6.8932, 'grad_norm': 349542547456.0, 'learning_rate': 1.1246612466124661e-05, 'epoch': 3.16}\n",
      "{'loss': 7.0677, 'grad_norm': 62626512896.0, 'learning_rate': 1.1178861788617887e-05, 'epoch': 3.16}\n",
      "{'loss': 7.8081, 'grad_norm': 298835902464.0, 'learning_rate': 1.1111111111111112e-05, 'epoch': 3.17}\n",
      "{'loss': 8.4968, 'grad_norm': 321415512064.0, 'learning_rate': 1.1043360433604337e-05, 'epoch': 3.17}\n",
      "{'loss': 9.0893, 'grad_norm': 17746675712.0, 'learning_rate': 1.0975609756097562e-05, 'epoch': 3.18}\n",
      "{'loss': 10.7826, 'grad_norm': 36019605504.0, 'learning_rate': 1.0907859078590785e-05, 'epoch': 3.18}\n",
      "{'loss': 11.0801, 'grad_norm': 105147113472.0, 'learning_rate': 1.0840108401084012e-05, 'epoch': 3.19}\n",
      "{'loss': 10.9916, 'grad_norm': 75055611904.0, 'learning_rate': 1.0772357723577237e-05, 'epoch': 3.19}\n",
      "{'loss': 11.3463, 'grad_norm': 7910630400.0, 'learning_rate': 1.070460704607046e-05, 'epoch': 3.2}\n",
      "{'loss': 10.2334, 'grad_norm': 1986905344.0, 'learning_rate': 1.0636856368563686e-05, 'epoch': 3.2}\n",
      "{'loss': 10.0281, 'grad_norm': 464597536.0, 'learning_rate': 1.0569105691056911e-05, 'epoch': 3.21}\n",
      "{'loss': 9.5813, 'grad_norm': 369968864.0, 'learning_rate': 1.0501355013550136e-05, 'epoch': 3.21}\n",
      "{'loss': 8.7246, 'grad_norm': 234540416.0, 'learning_rate': 1.0433604336043361e-05, 'epoch': 3.22}\n",
      "{'loss': 7.6333, 'grad_norm': 564068992.0, 'learning_rate': 1.0365853658536585e-05, 'epoch': 3.22}\n",
      "{'loss': 6.9519, 'grad_norm': 9258817536.0, 'learning_rate': 1.0298102981029812e-05, 'epoch': 3.23}\n",
      "{'loss': 7.0979, 'grad_norm': 1572904576.0, 'learning_rate': 1.0230352303523035e-05, 'epoch': 3.23}\n",
      "{'loss': 7.2495, 'grad_norm': 4025818880.0, 'learning_rate': 1.016260162601626e-05, 'epoch': 3.24}\n",
      "{'loss': 7.4647, 'grad_norm': 3969681152.0, 'learning_rate': 1.0094850948509485e-05, 'epoch': 3.24}\n",
      "{'loss': 7.635, 'grad_norm': 4062517248.0, 'learning_rate': 1.002710027100271e-05, 'epoch': 3.25}\n",
      "{'loss': 7.5193, 'grad_norm': 2488114176.0, 'learning_rate': 9.959349593495936e-06, 'epoch': 3.25}\n",
      "{'loss': 7.6612, 'grad_norm': 2471051776.0, 'learning_rate': 9.89159891598916e-06, 'epoch': 3.26}\n",
      "{'loss': 7.0316, 'grad_norm': 3004479488.0, 'learning_rate': 9.823848238482384e-06, 'epoch': 3.26}\n",
      "{'loss': 8.2804, 'grad_norm': 71074037760.0, 'learning_rate': 9.756097560975611e-06, 'epoch': 3.27}\n",
      "{'loss': 7.6521, 'grad_norm': 18783152128.0, 'learning_rate': 9.688346883468834e-06, 'epoch': 3.27}\n",
      "{'loss': 8.6484, 'grad_norm': 23800072192.0, 'learning_rate': 9.62059620596206e-06, 'epoch': 3.28}\n",
      "{'loss': 7.9042, 'grad_norm': 7141616128.0, 'learning_rate': 9.552845528455286e-06, 'epoch': 3.28}\n",
      "{'loss': 7.8784, 'grad_norm': 5385128960.0, 'learning_rate': 9.48509485094851e-06, 'epoch': 3.29}\n",
      "{'loss': 8.4284, 'grad_norm': 45172097024.0, 'learning_rate': 9.417344173441735e-06, 'epoch': 3.29}\n",
      "{'loss': 7.8605, 'grad_norm': 20748103680.0, 'learning_rate': 9.34959349593496e-06, 'epoch': 3.3}\n",
      "{'loss': 8.2193, 'grad_norm': 8265534464.0, 'learning_rate': 9.281842818428185e-06, 'epoch': 3.3}\n",
      "{'loss': 8.5011, 'grad_norm': 18840950784.0, 'learning_rate': 9.21409214092141e-06, 'epoch': 3.31}\n",
      "{'loss': 8.0325, 'grad_norm': 14180794368.0, 'learning_rate': 9.146341463414634e-06, 'epoch': 3.31}\n",
      "{'loss': 8.4309, 'grad_norm': 71049715712.0, 'learning_rate': 9.078590785907859e-06, 'epoch': 3.32}\n",
      "{'loss': 8.4783, 'grad_norm': 63535140864.0, 'learning_rate': 9.010840108401084e-06, 'epoch': 3.32}\n",
      "{'loss': 8.4475, 'grad_norm': 51154448384.0, 'learning_rate': 8.94308943089431e-06, 'epoch': 3.33}\n",
      "{'loss': 7.5029, 'grad_norm': 32754302976.0, 'learning_rate': 8.875338753387534e-06, 'epoch': 3.34}\n",
      "{'loss': 8.1689, 'grad_norm': 90902462464.0, 'learning_rate': 8.807588075880758e-06, 'epoch': 3.34}\n",
      "{'loss': 8.4026, 'grad_norm': 14455725056.0, 'learning_rate': 8.739837398373985e-06, 'epoch': 3.35}\n",
      "{'loss': 7.8623, 'grad_norm': 117360648192.0, 'learning_rate': 8.67208672086721e-06, 'epoch': 3.35}\n",
      "{'loss': 7.4302, 'grad_norm': 64371380224.0, 'learning_rate': 8.604336043360433e-06, 'epoch': 3.36}\n",
      "{'loss': 7.8793, 'grad_norm': 15051921408.0, 'learning_rate': 8.53658536585366e-06, 'epoch': 3.36}\n",
      "{'loss': 8.6912, 'grad_norm': 47080378368.0, 'learning_rate': 8.468834688346883e-06, 'epoch': 3.37}\n",
      "{'loss': 8.2123, 'grad_norm': 158990319616.0, 'learning_rate': 8.401084010840109e-06, 'epoch': 3.37}\n",
      "{'loss': 8.4341, 'grad_norm': 35546497024.0, 'learning_rate': 8.333333333333334e-06, 'epoch': 3.38}\n",
      "{'loss': 8.6639, 'grad_norm': 63829704704.0, 'learning_rate': 8.265582655826559e-06, 'epoch': 3.38}\n",
      "{'loss': 8.8088, 'grad_norm': 169239887872.0, 'learning_rate': 8.197831978319784e-06, 'epoch': 3.39}\n",
      "{'loss': 9.0456, 'grad_norm': 42850725888.0, 'learning_rate': 8.130081300813009e-06, 'epoch': 3.39}\n",
      "{'loss': 8.9668, 'grad_norm': 191891816448.0, 'learning_rate': 8.062330623306233e-06, 'epoch': 3.4}\n",
      "{'loss': 9.0536, 'grad_norm': 111566159872.0, 'learning_rate': 7.99457994579946e-06, 'epoch': 3.4}\n",
      "{'loss': 9.1355, 'grad_norm': 39622475776.0, 'learning_rate': 7.926829268292683e-06, 'epoch': 3.41}\n",
      "{'loss': 8.7448, 'grad_norm': 26806624256.0, 'learning_rate': 7.859078590785908e-06, 'epoch': 3.41}\n",
      "{'loss': 9.2886, 'grad_norm': 218007633920.0, 'learning_rate': 7.791327913279133e-06, 'epoch': 3.42}\n",
      "{'loss': 9.7531, 'grad_norm': 90551369728.0, 'learning_rate': 7.723577235772358e-06, 'epoch': 3.42}\n",
      "{'loss': 9.5758, 'grad_norm': 26161553408.0, 'learning_rate': 7.655826558265583e-06, 'epoch': 3.43}\n",
      "{'loss': 9.3244, 'grad_norm': 71530856448.0, 'learning_rate': 7.588075880758808e-06, 'epoch': 3.43}\n",
      "{'loss': 9.0541, 'grad_norm': 30578085888.0, 'learning_rate': 7.520325203252034e-06, 'epoch': 3.44}\n",
      "{'loss': 9.185, 'grad_norm': 30809040896.0, 'learning_rate': 7.452574525745258e-06, 'epoch': 3.44}\n",
      "{'loss': 9.1582, 'grad_norm': 13113884672.0, 'learning_rate': 7.384823848238483e-06, 'epoch': 3.45}\n",
      "{'loss': 9.2648, 'grad_norm': 326442385408.0, 'learning_rate': 7.317073170731707e-06, 'epoch': 3.45}\n",
      "{'loss': 9.3841, 'grad_norm': 155826454528.0, 'learning_rate': 7.249322493224933e-06, 'epoch': 3.46}\n",
      "{'loss': 9.1292, 'grad_norm': 5292526403584.0, 'learning_rate': 7.181571815718158e-06, 'epoch': 3.46}\n",
      "{'loss': 9.0009, 'grad_norm': 321390313472.0, 'learning_rate': 7.113821138211382e-06, 'epoch': 3.47}\n",
      "{'loss': 8.8632, 'grad_norm': 626079367168.0, 'learning_rate': 7.046070460704607e-06, 'epoch': 3.47}\n",
      "{'loss': 8.6214, 'grad_norm': 104079572992.0, 'learning_rate': 6.978319783197833e-06, 'epoch': 3.48}\n",
      "{'loss': 8.9148, 'grad_norm': 264411627520.0, 'learning_rate': 6.910569105691057e-06, 'epoch': 3.48}\n",
      "{'loss': 8.9098, 'grad_norm': 57424842752.0, 'learning_rate': 6.842818428184282e-06, 'epoch': 3.49}\n",
      "{'loss': 8.5304, 'grad_norm': 92567781376.0, 'learning_rate': 6.775067750677507e-06, 'epoch': 3.49}\n",
      "{'loss': 8.8362, 'grad_norm': 212064108544.0, 'learning_rate': 6.707317073170733e-06, 'epoch': 3.5}\n",
      "{'loss': 8.9194, 'grad_norm': 127882174464.0, 'learning_rate': 6.639566395663957e-06, 'epoch': 3.5}\n",
      "{'loss': 8.7313, 'grad_norm': 79614599168.0, 'learning_rate': 6.571815718157181e-06, 'epoch': 3.51}\n",
      "{'loss': 8.5813, 'grad_norm': 304931733504.0, 'learning_rate': 6.504065040650407e-06, 'epoch': 3.51}\n",
      "{'loss': 8.9032, 'grad_norm': 786563596288.0, 'learning_rate': 6.4363143631436324e-06, 'epoch': 3.52}\n",
      "{'loss': 8.6257, 'grad_norm': 45089648640.0, 'learning_rate': 6.368563685636857e-06, 'epoch': 3.52}\n",
      "{'loss': 8.6143, 'grad_norm': 745927278592.0, 'learning_rate': 6.300813008130081e-06, 'epoch': 3.53}\n",
      "{'loss': 8.7235, 'grad_norm': 86641532928.0, 'learning_rate': 6.233062330623306e-06, 'epoch': 3.53}\n",
      "{'loss': 8.5869, 'grad_norm': 79799975936.0, 'learning_rate': 6.165311653116531e-06, 'epoch': 3.54}\n",
      "{'loss': 9.1046, 'grad_norm': 437259632640.0, 'learning_rate': 6.0975609756097564e-06, 'epoch': 3.54}\n",
      "{'loss': 8.8859, 'grad_norm': 208383131648.0, 'learning_rate': 6.0298102981029816e-06, 'epoch': 3.55}\n",
      "{'loss': 8.089, 'grad_norm': 323772710912.0, 'learning_rate': 5.962059620596206e-06, 'epoch': 3.55}\n",
      "{'loss': 8.7928, 'grad_norm': 130199609344.0, 'learning_rate': 5.894308943089431e-06, 'epoch': 3.56}\n",
      "{'loss': 8.7287, 'grad_norm': 70551920640.0, 'learning_rate': 5.826558265582656e-06, 'epoch': 3.56}\n",
      "{'loss': 8.7307, 'grad_norm': 143196536832.0, 'learning_rate': 5.758807588075881e-06, 'epoch': 3.57}\n",
      "{'loss': 8.8944, 'grad_norm': 321823342592.0, 'learning_rate': 5.6910569105691056e-06, 'epoch': 3.57}\n",
      "{'loss': 8.4711, 'grad_norm': 423576403968.0, 'learning_rate': 5.623306233062331e-06, 'epoch': 3.58}\n",
      "{'loss': 8.9379, 'grad_norm': 105364692992.0, 'learning_rate': 5.555555555555556e-06, 'epoch': 3.58}\n",
      "{'loss': 8.9578, 'grad_norm': 148659994624.0, 'learning_rate': 5.487804878048781e-06, 'epoch': 3.59}\n",
      "{'loss': 8.7766, 'grad_norm': 371136888832.0, 'learning_rate': 5.420054200542006e-06, 'epoch': 3.59}\n",
      "{'loss': 8.1454, 'grad_norm': 278815703040.0, 'learning_rate': 5.35230352303523e-06, 'epoch': 3.6}\n",
      "{'loss': 8.6494, 'grad_norm': 109900398592.0, 'learning_rate': 5.2845528455284555e-06, 'epoch': 3.6}\n",
      "{'loss': 8.7281, 'grad_norm': 108205195264.0, 'learning_rate': 5.216802168021681e-06, 'epoch': 3.61}\n",
      "{'loss': 8.9379, 'grad_norm': 107408916480.0, 'learning_rate': 5.149051490514906e-06, 'epoch': 3.61}\n",
      "{'loss': 8.7963, 'grad_norm': 380126298112.0, 'learning_rate': 5.08130081300813e-06, 'epoch': 3.62}\n",
      "{'loss': 9.2515, 'grad_norm': 411430617088.0, 'learning_rate': 5.013550135501355e-06, 'epoch': 3.62}\n",
      "{'loss': 9.0777, 'grad_norm': 131355738112.0, 'learning_rate': 4.94579945799458e-06, 'epoch': 3.63}\n",
      "{'loss': 8.541, 'grad_norm': 170759766016.0, 'learning_rate': 4.8780487804878055e-06, 'epoch': 3.63}\n",
      "{'loss': 9.607, 'grad_norm': 380781363200.0, 'learning_rate': 4.81029810298103e-06, 'epoch': 3.64}\n",
      "{'loss': 9.7724, 'grad_norm': 347312848896.0, 'learning_rate': 4.742547425474255e-06, 'epoch': 3.64}\n",
      "{'loss': 8.811, 'grad_norm': 307058147328.0, 'learning_rate': 4.67479674796748e-06, 'epoch': 3.65}\n",
      "{'loss': 8.3711, 'grad_norm': 101932048384.0, 'learning_rate': 4.607046070460705e-06, 'epoch': 3.65}\n",
      "{'loss': 9.2213, 'grad_norm': 398237270016.0, 'learning_rate': 4.5392953929539295e-06, 'epoch': 3.66}\n",
      "{'loss': 8.9081, 'grad_norm': 140188073984.0, 'learning_rate': 4.471544715447155e-06, 'epoch': 3.66}\n",
      "{'loss': 8.7999, 'grad_norm': 255938478080.0, 'learning_rate': 4.403794037940379e-06, 'epoch': 3.67}\n",
      "{'loss': 9.0961, 'grad_norm': 217686720512.0, 'learning_rate': 4.336043360433605e-06, 'epoch': 3.68}\n",
      "{'loss': 9.1606, 'grad_norm': 60387385344.0, 'learning_rate': 4.26829268292683e-06, 'epoch': 3.68}\n",
      "{'loss': 9.1056, 'grad_norm': 464713809920.0, 'learning_rate': 4.200542005420054e-06, 'epoch': 3.69}\n",
      "{'loss': 9.2547, 'grad_norm': 726772678656.0, 'learning_rate': 4.1327913279132794e-06, 'epoch': 3.69}\n",
      "{'loss': 8.8973, 'grad_norm': 262930415616.0, 'learning_rate': 4.0650406504065046e-06, 'epoch': 3.7}\n",
      "{'loss': 8.8839, 'grad_norm': 270179991552.0, 'learning_rate': 3.99728997289973e-06, 'epoch': 3.7}\n",
      "{'loss': 9.0359, 'grad_norm': 198393626624.0, 'learning_rate': 3.929539295392954e-06, 'epoch': 3.71}\n",
      "{'loss': 9.214, 'grad_norm': 108955869184.0, 'learning_rate': 3.861788617886179e-06, 'epoch': 3.71}\n",
      "{'loss': 8.9652, 'grad_norm': 821555429376.0, 'learning_rate': 3.794037940379404e-06, 'epoch': 3.72}\n",
      "{'loss': 8.9174, 'grad_norm': 308838629376.0, 'learning_rate': 3.726287262872629e-06, 'epoch': 3.72}\n",
      "{'loss': 9.7846, 'grad_norm': 1724589932544.0, 'learning_rate': 3.6585365853658537e-06, 'epoch': 3.73}\n",
      "{'loss': 9.6286, 'grad_norm': 844369362944.0, 'learning_rate': 3.590785907859079e-06, 'epoch': 3.73}\n",
      "{'loss': 9.3527, 'grad_norm': 519670759424.0, 'learning_rate': 3.5230352303523035e-06, 'epoch': 3.74}\n",
      "{'loss': 8.9451, 'grad_norm': 175543287808.0, 'learning_rate': 3.4552845528455287e-06, 'epoch': 3.74}\n",
      "{'loss': 9.2639, 'grad_norm': 1107644252160.0, 'learning_rate': 3.3875338753387534e-06, 'epoch': 3.75}\n",
      "{'loss': 9.2234, 'grad_norm': 277019852800.0, 'learning_rate': 3.3197831978319785e-06, 'epoch': 3.75}\n",
      "{'loss': 9.4446, 'grad_norm': 312269275136.0, 'learning_rate': 3.2520325203252037e-06, 'epoch': 3.76}\n",
      "{'loss': 9.2744, 'grad_norm': 451128688640.0, 'learning_rate': 3.1842818428184284e-06, 'epoch': 3.76}\n",
      "{'loss': 8.8184, 'grad_norm': 202525884416.0, 'learning_rate': 3.116531165311653e-06, 'epoch': 3.77}\n",
      "{'loss': 9.1394, 'grad_norm': 309431009280.0, 'learning_rate': 3.0487804878048782e-06, 'epoch': 3.77}\n",
      "{'loss': 9.6965, 'grad_norm': 610546548736.0, 'learning_rate': 2.981029810298103e-06, 'epoch': 3.78}\n",
      "{'loss': 9.5663, 'grad_norm': 803522871296.0, 'learning_rate': 2.913279132791328e-06, 'epoch': 3.78}\n",
      "{'loss': 9.0893, 'grad_norm': 107914985472.0, 'learning_rate': 2.8455284552845528e-06, 'epoch': 3.79}\n",
      "{'loss': 9.7363, 'grad_norm': 2797038206976.0, 'learning_rate': 2.777777777777778e-06, 'epoch': 3.79}\n",
      "{'loss': 9.1296, 'grad_norm': 272825188352.0, 'learning_rate': 2.710027100271003e-06, 'epoch': 3.8}\n",
      "{'loss': 9.0244, 'grad_norm': 493408387072.0, 'learning_rate': 2.6422764227642278e-06, 'epoch': 3.8}\n",
      "{'loss': 9.2246, 'grad_norm': 505009143808.0, 'learning_rate': 2.574525745257453e-06, 'epoch': 3.81}\n",
      "{'loss': 9.1816, 'grad_norm': 225205223424.0, 'learning_rate': 2.5067750677506776e-06, 'epoch': 3.81}\n",
      "{'loss': 9.5214, 'grad_norm': 146722553856.0, 'learning_rate': 2.4390243902439027e-06, 'epoch': 3.82}\n",
      "{'loss': 9.781, 'grad_norm': 1105379196928.0, 'learning_rate': 2.3712737127371275e-06, 'epoch': 3.82}\n",
      "{'loss': 9.1172, 'grad_norm': 98986926080.0, 'learning_rate': 2.3035230352303526e-06, 'epoch': 3.83}\n",
      "{'loss': 9.5236, 'grad_norm': 93694984192.0, 'learning_rate': 2.2357723577235773e-06, 'epoch': 3.83}\n",
      "{'loss': 9.0361, 'grad_norm': 660376125440.0, 'learning_rate': 2.1680216802168024e-06, 'epoch': 3.84}\n",
      "{'loss': 9.4335, 'grad_norm': 426304077824.0, 'learning_rate': 2.100271002710027e-06, 'epoch': 3.84}\n",
      "{'loss': 9.2996, 'grad_norm': 276906311680.0, 'learning_rate': 2.0325203252032523e-06, 'epoch': 3.85}\n",
      "{'loss': 9.6735, 'grad_norm': 471388913664.0, 'learning_rate': 1.964769647696477e-06, 'epoch': 3.85}\n",
      "{'loss': 9.2453, 'grad_norm': 339328040960.0, 'learning_rate': 1.897018970189702e-06, 'epoch': 3.86}\n",
      "{'loss': 9.4654, 'grad_norm': 503158243328.0, 'learning_rate': 1.8292682926829268e-06, 'epoch': 3.86}\n",
      "{'loss': 9.8793, 'grad_norm': 883528105984.0, 'learning_rate': 1.7615176151761518e-06, 'epoch': 3.87}\n",
      "{'loss': 9.3134, 'grad_norm': 169854779392.0, 'learning_rate': 1.6937669376693767e-06, 'epoch': 3.87}\n",
      "{'loss': 9.287, 'grad_norm': 673949417472.0, 'learning_rate': 1.6260162601626018e-06, 'epoch': 3.88}\n",
      "{'loss': 9.5607, 'grad_norm': 107515117568.0, 'learning_rate': 1.5582655826558265e-06, 'epoch': 3.88}\n",
      "{'loss': 9.1103, 'grad_norm': 1024170000384.0, 'learning_rate': 1.4905149051490515e-06, 'epoch': 3.89}\n",
      "{'loss': 9.3859, 'grad_norm': 581891522560.0, 'learning_rate': 1.4227642276422764e-06, 'epoch': 3.89}\n",
      "{'loss': 10.327, 'grad_norm': 1849118556160.0, 'learning_rate': 1.3550135501355015e-06, 'epoch': 3.9}\n",
      "{'loss': 10.044, 'grad_norm': 294958006272.0, 'learning_rate': 1.2872628726287264e-06, 'epoch': 3.9}\n",
      "{'loss': 9.504, 'grad_norm': 677584633856.0, 'learning_rate': 1.2195121951219514e-06, 'epoch': 3.91}\n",
      "{'loss': 9.4713, 'grad_norm': 413693870080.0, 'learning_rate': 1.1517615176151763e-06, 'epoch': 3.91}\n",
      "{'loss': 9.67, 'grad_norm': 377592020992.0, 'learning_rate': 1.0840108401084012e-06, 'epoch': 3.92}\n",
      "{'loss': 9.1345, 'grad_norm': 651479941120.0, 'learning_rate': 1.0162601626016261e-06, 'epoch': 3.92}\n",
      "{'loss': 9.8093, 'grad_norm': 225403813888.0, 'learning_rate': 9.48509485094851e-07, 'epoch': 3.93}\n",
      "{'loss': 9.1522, 'grad_norm': 630616817664.0, 'learning_rate': 8.807588075880759e-07, 'epoch': 3.93}\n",
      "{'loss': 9.4562, 'grad_norm': 1079816814592.0, 'learning_rate': 8.130081300813009e-07, 'epoch': 3.94}\n",
      "{'loss': 9.1718, 'grad_norm': 100557185024.0, 'learning_rate': 7.452574525745257e-07, 'epoch': 3.94}\n",
      "{'loss': 9.3213, 'grad_norm': 428111396864.0, 'learning_rate': 6.775067750677508e-07, 'epoch': 3.95}\n",
      "{'loss': 9.7197, 'grad_norm': 786664587264.0, 'learning_rate': 6.097560975609757e-07, 'epoch': 3.95}\n",
      "{'loss': 9.9811, 'grad_norm': 244949925888.0, 'learning_rate': 5.420054200542006e-07, 'epoch': 3.96}\n",
      "{'loss': 9.4294, 'grad_norm': 125195788288.0, 'learning_rate': 4.742547425474255e-07, 'epoch': 3.96}\n",
      "{'loss': 9.0943, 'grad_norm': 90315374592.0, 'learning_rate': 4.0650406504065046e-07, 'epoch': 3.97}\n",
      "{'loss': 9.3744, 'grad_norm': 665007882240.0, 'learning_rate': 3.387533875338754e-07, 'epoch': 3.97}\n",
      "{'loss': 9.2073, 'grad_norm': 383261638656.0, 'learning_rate': 2.710027100271003e-07, 'epoch': 3.98}\n",
      "{'loss': 9.3053, 'grad_norm': 132095262720.0, 'learning_rate': 2.0325203252032523e-07, 'epoch': 3.98}\n",
      "{'loss': 9.3135, 'grad_norm': 336718266368.0, 'learning_rate': 1.3550135501355015e-07, 'epoch': 3.99}\n",
      "{'loss': 9.4576, 'grad_norm': 414006509568.0, 'learning_rate': 6.775067750677508e-08, 'epoch': 3.99}\n",
      "{'loss': 10.2696, 'grad_norm': 2043196080128.0, 'learning_rate': 0.0, 'epoch': 4.0}\n",
      "{'train_runtime': 4643.2896, 'train_samples_per_second': 8.482, 'train_steps_per_second': 1.697, 'train_loss': 11.376474951971606, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7880, training_loss=11.376474951971606, metrics={'train_runtime': 4643.2896, 'train_samples_per_second': 8.482, 'train_steps_per_second': 1.697, 'train_loss': 11.376474951971606, 'epoch': 4.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Response: i feel depressed, these all in. and's your the ways on both is that just at, as needs this be you to activities can more such levels of. career and\n"
     ]
    }
   ],
   "source": [
    "def predict_response(input_text, model, tokenizer, max_length=512):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=50,\n",
    "    temperature=0.5 ,\n",
    "    top_k=50,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id)\n",
    "    predicted_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "    return predicted_text     \n",
    "\n",
    "# Example usage\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')  # Make sure the model is on the right device\n",
    "input_text = \"i feel depressed\"\n",
    "\n",
    "response = predict_response(input_text, model, tokenizer)\n",
    "print(\"Predicted Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
