{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: \n",
    "\n",
    "1. find a base model (BERT, LLAMMA, etc)\n",
    "2. train the model\n",
    "3. finetune the model with data from mental health counseling dataset\n",
    "4. figure out how to get data to show on our report\n",
    "5. Graph data on sentiment analysis\n",
    "6. Make a front end\n",
    "7. Make a back end (api calls to model and then returns to front end)\n",
    "8. Figure out how to preprocess the data for the model and see if it is better to analyze the sentiment then give the model the information prior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: torchinfo in c:\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\python311\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\winto\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torchinfo\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install --user matplotlib\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\") # requires a nvidia GPU with CUDA installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  I'm going through some things with my feelings...   \n",
       "1  I'm going through some things with my feelings...   \n",
       "2  I'm going through some things with my feelings...   \n",
       "3  I'm going through some things with my feelings...   \n",
       "4  I'm going through some things with my feelings...   \n",
       "\n",
       "                                            Response  \n",
       "0  If everyone thinks you're worthless, then mayb...  \n",
       "1  Hello, and thank you for your question and see...  \n",
       "2  First thing I'd suggest is getting the sleep y...  \n",
       "3  Therapy is essential for those that are feelin...  \n",
       "4  I first want to let you know that you are not ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"mental_health_convo_set.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See different types of input and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        4\n",
       "Hello there.  You ask about being nervous and shaky walking in to your therapy session and want to know if its normal? ...  I realize there a few ways to look at this.  I presume you weren't anticipating feeling this way; and probably hoped to feel the opposite..  Well, my initial response is yes, sure, it can be within reason to feel this way.  Have you been in therapy before? Is this somewhat new? That could be part of the reason. But either way; new or not, I think when are entering into a meeting that holds potential evaluation of deep things about you and your heart and soul, it can cause anyone to tremble. The soul can be anticipating some things could be shaken up here, and it can feel scary to look at these things and then change.  Looking deep at our life can feel daunting and scary; so your response just might be regards to potential growth trying to happen.   OR, is there something about the therapist you don't feel confident about?  This too might be in play as a reason for your feelings...  Maybe you lack confidence in that therapist ?  Have you let your therapist know how you feel?  That would be good to explore...I would like to encourage you to look at these ideas.  Hope it helps.   Let me knowKindly,keithkeithcounseling.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            3\n",
       "Hello. First, I am so sorry you are experiencing these feelings. They can be intense, I will do my best to offer some suggestions or thoughts that I hope will be helpful to you. There could be a number of things occurring. Therapy is a delicate, private decision and I would first like to commend you for the fact that you are not giving up, that you are working to figure this out, and make this work, it sounds like you are engaged and motivated to receive support from a professional, your continued  dedication and motivation will take you far. I would first start by asking if you have discussed this with your therapist, if you feel comfortable enough telling your therapist what is going on, maybe inform the therapist that  that you feel nervous and shaky. I am a firm believer in open communication between the client and therapist as this builds a healthy therapeutic relationship that yields positive outcomes, if this can be obtained and well received. This is YOUR time for healing and therapy should be a safe, supportive environment to not only process but to seek support and guidance from a professional who can help you move past the barriers. If you feel you are comfortable and able to speak to your therapist, that would be my first suggestion, is to tell he or she how you are feeling. If they know then they can help determine the potential cause and allow you to process and move forward. If this is left un resolved it will be hard for you to move forward. If you are not comfortable discussing this with your therapist, this may be something to take into consideration and worthy of thinking about: why you are not comfortable speaking to the therapist. I understand this is difficult. If I may offer one more suggestion, breathing exercises are very beneficial. Remind yourself what you are working to achieve, close your eyes in a safe moment and breathe in and out slowly, in slowly through your nose and out through your mouth with pursed lips. Breathe in for approximately 5-10 seconds, then let it out slowly. Be sure and do this when you are in private, and feel safe environment. When you begin, I suggest putting your hand on your stomach, over your belly button to feel yourself actually taking in those deep breaths. I know it may sound kind of silly but they really work and are incredibly helpful. We often forget to breathe, especially when we  are feeling anxious. You are supported here and try taking yourself through the above thought process and breathing and practice the breathing several times a day. I hope this shaky and uneasy feeling eases. Wishing you the very best!Laura Cassity, LMSW, LMAC    3\n",
       "If you have only been to a couple of sessions, it makes sense that you might still feel apprehensive at first. Therapy is hard work! You may be talking about some things that you never talked to anyone about before. Opening up to stranger can be scary. After you feel comfortable with your counselor, and trust has built up and you feel understood in session, you should feel more relaxed. I would encourage you to talk to your counselor about feeling a little shaky. Sharing what the process is like for you is important in your work. If you still feel unsure about sharing after several sessions, it is important to take a look at that and try to understand where that may be coming from. For example, are you and the therapist not a good fit? But, again if you are just starting out in working together, feeling a little bit nervous makes perfect sense, and I encourage you to give it a bit more time and to talk to your therapist about how you are feeling.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        3\n",
       "Counseling ends when the client has received the maximum benefit from the therapist. Even if the therapist believes the client is not making progress, the client may feel they are improving and receiving a benefit. And the therapist may see a benefit and the client does not. It is best to have ongoing dialogue with the client to determine when termination is appropriate.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   3\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ..\n",
       "The only two people who know the answer to your question are your husband and the prostitute.The question you did and can answer is the reason you would doubt your husband, which is bc of his multiple stories.Ideally your husband cares to restore your sense of confidence in the stories he tells you.If you state your doubts and your interest for the truth, ideally he will produce enough evidence of the truth so you will have facts and can make sense of them.   Hopefully the two of you will do this sense making together, especially if he did have sex w the prostititute.If he's unwilling to care about restoring your trust in him, then this is a different problem entirely.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   1\n",
       "Hello, The truth is that you will never know unless your husband decides to be upfront about the details to gain your trust.  One thing is for sure though, not knowing and having this uncertainty in your heart will push your husband and you further away from being able to repair the marriage.  The best thing you both can do is seek professional help to navigate this issue and start doing damage control.  It sounds as if you are committed to this marriage and I am sure your husband is too.  It will take some time and purpose, but you can recover from this if you both commit.  Don't wait and start working the steps to find peace of mind and a way to reconnect with the man you love.  Mirella~Image and Likeness Counseling                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "It sounds like you've been living with this uncertainty for those couple years since this happened.  The reality is you won't ever \"know\" - mostly because of the various versions your husband has provided you.  Infidelity, though painful, does not have to kill a marriage.  Secrecy and dishonesty certainly will though.   I encourage you and your husband to seek therapy together with someone who specializes in couples work.  The longer you wait to do so, the more damage is done to whatever connection you have and the greater the distrust will become. Please get qualified help, for your and your husband's sake.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 1\n",
       "I've been in this situation before and have some insight to share with you.  In my experience, he was lying and trying to cover it up. By pushing you to std testing, he's distracting you so he can shift the guilt he feels and blame it on you. In a guilty man's mind I believe he's thinking-...if I cheated...you must have as well....but you're much worse than I because it's okay for me to cheat...but not you...now you're a cheating dirty slut...just like that prostitute Men believe they're entitled to treat women and children like property. Often they use intimidation and violence to control us.  He'll never admit to cheating, he'll never apologize and he'll do it again and again. Truly they don't think it's a big deal, it's just their way of being social. They desperately want us to accept it, perhaps join in the act.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
       "hmm this is a tough one!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1\n",
       "Name: count, Length: 2480, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Context'].value_counts()\n",
    "df['Response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the labels into encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "0       0.001139\n",
       "522     0.000854\n",
       "614     0.000854\n",
       "1171    0.000854\n",
       "250     0.000854\n",
       "          ...   \n",
       "1925    0.000285\n",
       "544     0.000285\n",
       "1393    0.000285\n",
       "1142    0.000285\n",
       "2458    0.000285\n",
       "Name: proportion, Length: 2480, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "df['Response'] = le.fit_transform(df['Response'])\n",
    "# check class distribution\n",
    "df['Response'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_labels = df['Context'], df['Response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, BertTokenizerFast\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roberta Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# Import Roberta pretrained model\n",
    "bert = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBer Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# Load the DistilBert tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Import the DistilBert pretrained model\n",
    "bert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2003,  1037,  4487, 16643,  2140, 14324,  2944,  1012,\n",
      "           102],\n",
      "        [  101,  2951,  2003,  3514,   102,     0,     0,     0,     0,     0,\n",
      "             0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "text = [\"this is a distil bert model.\",\"data is oil\"]\n",
    "# Encode the text\n",
    "encoded_input = tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 10)\n",
    "# Based on the histogram we are selecting the max len as 8\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WinTo\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "   def __init__(self, bert):      \n",
    "       super(BERT_Arch, self).__init__()\n",
    "       self.bert = bert \n",
    "      \n",
    "       # dropout layer\n",
    "       self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "       # relu activation function\n",
    "       self.relu =  nn.ReLU()\n",
    "       # dense layer\n",
    "       self.fc1 = nn.Linear(768,512)\n",
    "       self.fc2 = nn.Linear(512,256)\n",
    "       self.fc3 = nn.Linear(256,5)\n",
    "       #softmax activation function\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "       #define the forward pass\n",
    "   def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      \n",
    "      x = self.fc2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "   \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "BERT_Arch                                               --\n",
       "├─DistilBertModel: 1-1                                  --\n",
       "│    └─Embeddings: 2-1                                  --\n",
       "│    │    └─Embedding: 3-1                              (23,440,896)\n",
       "│    │    └─Embedding: 3-2                              (393,216)\n",
       "│    │    └─LayerNorm: 3-3                              (1,536)\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    └─Transformer: 2-2                                 --\n",
       "│    │    └─ModuleList: 3-5                             (42,527,232)\n",
       "├─Dropout: 1-2                                          --\n",
       "├─ReLU: 1-3                                             --\n",
       "├─Linear: 1-4                                           393,728\n",
       "├─Linear: 1-5                                           131,328\n",
       "├─Linear: 1-6                                           1,285\n",
       "├─LogSoftmax: 1-7                                       --\n",
       "================================================================================\n",
       "Total params: 66,889,221\n",
       "Trainable params: 526,341\n",
       "Non-trainable params: 66,362,880\n",
       "================================================================================"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "for param in bert.parameters():\n",
    "      param.requires_grad = False\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WinTo\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35403226 1.41612903 1.41612903 ... 1.41612903 1.41612903 1.41612903]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(class_weight= 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_labels = df['Context'], df['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# convert class weights to tensor\u001b[39;00m\n\u001b[0;32m      2\u001b[0m weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(class_wts,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m----> 3\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loss function\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cross_entropy \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss(weight\u001b[38;5;241m=\u001b[39mweights) \n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# convert class weights to tensor\n",
    "weights = torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 200\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step,    len(train_dataloader)))\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch] \n",
    "    sent_id, mask, labels = batch\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # clear calculated gradients\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    # We are not using learning rate scheduler as of now\n",
    "    # lr_sch.step()\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "   # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# append training and validation loss\u001b[39;00m\n\u001b[0;32m      9\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Batch \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m  of  \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, \u001b[38;5;28mlen\u001b[39m(train_dataloader)))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Send the batch to the device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m sent_id, mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Zero the gradients before running the backward pass.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  Batch \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m  of  \u001b[39m\u001b[38;5;132;01m{:>5,}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, \u001b[38;5;28mlen\u001b[39m(train_dataloader)))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Send the batch to the device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m     15\u001b[0m sent_id, mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Zero the gradients before running the backward pass.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
